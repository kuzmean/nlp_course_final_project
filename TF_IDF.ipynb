{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nuvUJka08epQ"
      },
      "source": [
        "# Проект по классификации токсичных комментариев. TF-IDF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IbMXq0ul8epR"
      },
      "source": [
        "Необходимо обучить модель классифицировать комментарии на позитивные и негативные. В распоряжении набор данных с разметкой о токсичности.\n",
        "\n",
        "Цель постройть модель со значением метрики качества *F1* не меньше 0.75.\n",
        "\n",
        "**Описание данных**\n",
        "\n",
        "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tu0mFzkG8epS"
      },
      "source": [
        "## Подготовка"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fvPma-DH8epT",
        "outputId": "4e7d5591-9ac6-4ad6-d5c8-7d2b792e9e54"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: catboost in /opt/conda/lib/python3.9/site-packages (1.0.3)\n",
            "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.9/site-packages (from catboost) (3.3.4)\n",
            "Requirement already satisfied: scipy in /opt/conda/lib/python3.9/site-packages (from catboost) (1.9.1)\n",
            "Requirement already satisfied: graphviz in /opt/conda/lib/python3.9/site-packages (from catboost) (0.20.1)\n",
            "Requirement already satisfied: six in /opt/conda/lib/python3.9/site-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /opt/conda/lib/python3.9/site-packages (from catboost) (1.2.4)\n",
            "Requirement already satisfied: plotly in /opt/conda/lib/python3.9/site-packages (from catboost) (5.4.0)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /opt/conda/lib/python3.9/site-packages (from catboost) (1.21.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.9/site-packages (from pandas>=0.24.0->catboost) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.9/site-packages (from pandas>=0.24.0->catboost) (2021.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib->catboost) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.9/site-packages (from matplotlib->catboost) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /opt/conda/lib/python3.9/site-packages (from matplotlib->catboost) (2.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.9/site-packages (from matplotlib->catboost) (8.4.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /opt/conda/lib/python3.9/site-packages (from plotly->catboost) (8.0.1)\n",
            "Requirement already satisfied: transformers in /opt/conda/lib/python3.9/site-packages (4.12.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.9/site-packages (from transformers) (2022.8.17)\n",
            "Requirement already satisfied: filelock in /opt/conda/lib/python3.9/site-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.9/site-packages (from transformers) (0.9.1)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /opt/conda/lib/python3.9/site-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.9/site-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.9/site-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: requests in /opt/conda/lib/python3.9/site-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.9/site-packages (from transformers) (4.61.2)\n",
            "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.9/site-packages (from transformers) (0.0.53)\n",
            "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.9/site-packages (from transformers) (1.21.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.3.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.9/site-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests->transformers) (2022.6.15)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests->transformers) (1.26.6)\n",
            "Requirement already satisfied: six in /opt/conda/lib/python3.9/site-packages (from sacremoses->transformers) (1.16.0)\n",
            "Requirement already satisfied: click in /opt/conda/lib/python3.9/site-packages (from sacremoses->transformers) (8.1.3)\n",
            "Requirement already satisfied: joblib in /opt/conda/lib/python3.9/site-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: spacy in /opt/conda/lib/python3.9/site-packages (3.2.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.9/site-packages (from spacy) (4.61.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.9/site-packages (from spacy) (21.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.9/site-packages (from spacy) (2.25.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.9/site-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.9/site-packages (from spacy) (1.0.3)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /opt/conda/lib/python3.9/site-packages (from spacy) (0.7.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.9/site-packages (from spacy) (3.0.7)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /opt/conda/lib/python3.9/site-packages (from spacy) (0.6.2)\n",
            "Requirement already satisfied: setuptools in /opt/conda/lib/python3.9/site-packages (from spacy) (49.6.0.post20210108)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.9/site-packages (from spacy) (1.0.8)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /opt/conda/lib/python3.9/site-packages (from spacy) (3.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from spacy) (2.0.6)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.9/site-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /opt/conda/lib/python3.9/site-packages (from spacy) (1.8.2)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /opt/conda/lib/python3.9/site-packages (from spacy) (8.0.17)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /opt/conda/lib/python3.9/site-packages (from spacy) (0.10.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.9/site-packages (from spacy) (1.21.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /opt/conda/lib/python3.9/site-packages (from spacy) (2.4.4)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /opt/conda/lib/python3.9/site-packages (from spacy) (0.4.2)\n",
            "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.9/site-packages (from spacy) (3.0.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging>=20.0->spacy) (2.4.7)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /opt/conda/lib/python3.9/site-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy) (4.3.0)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.6)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.6.15)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.9/site-packages (from typer<0.5.0,>=0.3.0->spacy) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.9/site-packages (from jinja2->spacy) (2.1.1)\n",
            "Collecting en-core-web-sm==3.2.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.2.0/en_core_web_sm-3.2.0-py3-none-any.whl (13.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 13.9 MB 1.2 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.3.0,>=3.2.0 in /opt/conda/lib/python3.9/site-packages (from en-core-web-sm==3.2.0) (3.2.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.0.8)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (4.61.2)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /opt/conda/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.8.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.6)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.4.2)\n",
            "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.1)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /opt/conda/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.6.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (21.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /opt/conda/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.10.1)\n",
            "Requirement already satisfied: setuptools in /opt/conda/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (49.6.0.post20210108)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.3.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /opt/conda/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.10)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /opt/conda/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.4.4)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /opt/conda/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (8.0.17)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.21.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.25.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.7)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.0.3)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.7.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.8)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging>=20.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.4.7)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /opt/conda/lib/python3.9/site-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (5.2.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (4.3.0)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2022.6.15)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.26.6)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.9/site-packages (from typer<0.5.0,>=0.3.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.9/site-packages (from jinja2->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.1.1)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        }
      ],
      "source": [
        "!pip install catboost\n",
        "!pip install transformers\n",
        "!pip install spacy\n",
        "!python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVEEUMn88epY",
        "outputId": "1be0fe4b-e5e3-48b9-e80b-c34c8a7af4f0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import f1_score\n",
        "from tqdm.notebook import tqdm\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import transformers\n",
        "import re\n",
        "import spacy\n",
        "from tqdm import notebook\n",
        "from tqdm.notebook import tqdm\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.dummy import DummyClassifier\n",
        "import transformers\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-dC1VGcO8epa"
      },
      "outputs": [],
      "source": [
        "pth1 = '/datasets/toxic_comments.csv'\n",
        "pth2 = 'https://code.s3.yandex.net/datasets/toxic_comments.csv'\n",
        "\n",
        "try:\n",
        "    df = pd.read_csv(pth1)\n",
        "except:\n",
        "    df = pd.read_csv(pth2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bE08Cxi28epb"
      },
      "source": [
        "Избавимся от ненужного столбца, который копирует индексы"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uZniLzSl8epc"
      },
      "outputs": [],
      "source": [
        "df = df.drop('Unnamed: 0', axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDrEJLIg8epe"
      },
      "source": [
        "### EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "IgmEi6Vw8epe",
        "outputId": "2f6bd861-8ea9-49b6-c0b3-e57b9c85c4d4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    Explanation\\nWhy the edits made under my usern...\n",
              "1    D'aww! He matches this background colour I'm s...\n",
              "2    Hey man, I'm really not trying to edit war. It...\n",
              "3    \"\\nMore\\nI can't make any real suggestions on ...\n",
              "4    You, sir, are my hero. Any chance you remember...\n",
              "Name: text, dtype: object"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.text[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_-h4r6G8epf",
        "outputId": "26105546-dbed-4461-85a3-3c166bcc02a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 159292 entries, 0 to 159291\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count   Dtype \n",
            "---  ------  --------------   ----- \n",
            " 0   text    159292 non-null  object\n",
            " 1   toxic   159292 non-null  int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 2.4+ MB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PeJvKr_g8epg",
        "outputId": "f6e20339-aa17-40e2-ae14-8ce56eb50993"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "text     0.0\n",
              "toxic    0.0\n",
              "dtype: float64"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df[df.text.duplicated()].sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dB_P5Xaa8epg",
        "outputId": "d268632d-12c0-4964-cd97-117a0425d81a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "text     0\n",
              "toxic    0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8SH1w4z8eph"
      },
      "source": [
        "Рассмотрим баланс классов, так как для обучения нам нужны обьекты как положительного, так и отрицательного класса"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "DOOmTRIO8eph",
        "outputId": "9be941f0-4c14-4479-ac24-a182e4903a93"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "sns.countplot(x=df['toxic']);\n",
        "plt.title('Сравнение балланса классов');\n",
        "plt.xlabel(\"Токсичность\");\n",
        "plt.ylabel(\"Количество\");\n",
        "plt.grid(False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WvGPI6TY8epi",
        "outputId": "ef16dfc6-e188-4fd7-e844-6001b1fa205e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    143106\n",
              "1     16186\n",
              "Name: toxic, dtype: int64"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['toxic'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XI6HPQ1z8epi"
      },
      "source": [
        "Классы несблансированы, но в нашей задаче это достаточно предсказуемо,  потому что обычно токсичных комментариев меньше"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSMa6lfa8epj"
      },
      "source": [
        "### Лемматизируем и очистим текст"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMIXZBt68epj"
      },
      "source": [
        "Напишем функцию лемматизации и очистки текста"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "THlOw2LD8epj"
      },
      "outputs": [],
      "source": [
        "corpus = df['text'].astype('str')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q7Uspzvf8epk"
      },
      "outputs": [],
      "source": [
        "nlp = spacy.load('en_core_web_sm')\n",
        "regex = re.compile(r'[^a-zA-Z]')\n",
        "\n",
        "def lemmatize_and_clear_text(text):\n",
        "    doc = nlp(text)\n",
        "    lem_text = [token.lemma_.lower() for token in doc if token.is_alpha]\n",
        "    text_out = ' '.join(lem_text)\n",
        "    text_out = regex.sub(' ', text_out)\n",
        "    return text_out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rpuNftzj8epk"
      },
      "outputs": [],
      "source": [
        "corpus_lemma = corpus.apply(lemmatize_and_clear_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSDqbcqy8epl"
      },
      "source": [
        "Проверим"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YhOo-0XT8epl",
        "outputId": "d0fd2524-bad7-4a21-a93f-ab7f07ae1d9a",
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Исходный текст: Explanation\n",
            "Why the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27\n",
            "Лемматизированный текст: explanation why the edit make under my username hardcore metallica fan be revert they be vandalism just closure on some gas after i vote at new york dolls fac and please do remove the template from the talk page since i retire\n"
          ]
        }
      ],
      "source": [
        "print(\"Исходный текст:\", corpus[0])\n",
        "print(\"Лемматизированный текст:\", corpus_lemma[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9tA-nDp8epm"
      },
      "source": [
        "### Делим выборки"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pYU7OhWD8epm"
      },
      "outputs": [],
      "source": [
        "df['text_lemma'] = corpus_lemma\n",
        "features = df['text_lemma']\n",
        "target = df['toxic']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kscrpqEQ8epm"
      },
      "outputs": [],
      "source": [
        "RANDOM_STATE = 42"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rr9Is5Uo8epn"
      },
      "outputs": [],
      "source": [
        "features_train, features_test, target_train, target_test = train_test_split(features, target, stratify=target,\n",
        "                                                                            test_size=0.2, random_state=RANDOM_STATE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "diLWXyo58epo"
      },
      "source": [
        "### Векторизация корпусов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ymPcsZq8epo"
      },
      "outputs": [],
      "source": [
        "tf_idf = TfidfVectorizer(ngram_range=(1, 1), stop_words='english', min_df=3, max_df=0.9,\n",
        "    strip_accents='unicode', use_idf=True, smooth_idf=True, sublinear_tf=True)\n",
        "tf_idf_train = tf_idf.fit_transform(features_train)\n",
        "tf_idf_test = tf_idf.transform(features_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zSbKNmAp8epp",
        "outputId": "ec0c226b-9cb7-45e9-abe5-65a4e105a150"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Размер матрицы: (127433, 36283) (31859, 36283)\n"
          ]
        }
      ],
      "source": [
        "print(\"Размер матрицы:\", tf_idf_train.shape, tf_idf_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvXJFSRu8epp"
      },
      "source": [
        "## Обучение"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Bgpg0sB8epq"
      },
      "source": [
        "### LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_--ZkGsU8ept"
      },
      "outputs": [],
      "source": [
        "cv = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsX3aRLbwFI4",
        "outputId": "e93d69c9-f0e3-4dca-d041-59b9bcbf0508"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5; 1/1] START ............................................................\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 1/1] END ........................................... total time=  33.9s\n",
            "[CV 2/5; 1/1] START ............................................................\n",
            "[CV 2/5; 1/1] END ........................................... total time=  28.9s\n",
            "[CV 3/5; 1/1] START ............................................................\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5; 1/1] END ........................................... total time=  29.8s\n",
            "[CV 4/5; 1/1] START ............................................................\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 1/1] END ........................................... total time=  32.0s\n",
            "[CV 5/5; 1/1] START ............................................................\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 1/1] END ........................................... total time=  34.1s\n",
            "0.7498105476559265\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "log_reg_model = LogisticRegression(class_weight='balanced', random_state=RANDOM_STATE)\n",
        "\n",
        "param_grid = {\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(log_reg_model, param_grid, scoring='f1', cv=cv, n_jobs=-1, verbose=10)\n",
        "grid_search.fit(tf_idf_train, target_train)\n",
        "\n",
        "log_reg_score = grid_search.best_score_\n",
        "print(log_reg_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MeExMvjB8eps"
      },
      "source": [
        "### RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        },
        "id": "i8YaqEeF8ept",
        "outputId": "2920de8e-95e2-4fd2-b971-dd1dcaa32439"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
            "[CV 1/5; 1/9] START max_depth=3, n_estimators=10................................\n",
            "[CV 1/5; 1/9] END ..............max_depth=3, n_estimators=10; total time=   0.3s\n",
            "[CV 2/5; 1/9] START max_depth=3, n_estimators=10................................\n",
            "[CV 2/5; 1/9] END ..............max_depth=3, n_estimators=10; total time=   0.3s\n",
            "[CV 3/5; 1/9] START max_depth=3, n_estimators=10................................\n",
            "[CV 3/5; 1/9] END ..............max_depth=3, n_estimators=10; total time=   0.3s\n",
            "[CV 4/5; 1/9] START max_depth=3, n_estimators=10................................\n",
            "[CV 4/5; 1/9] END ..............max_depth=3, n_estimators=10; total time=   0.3s\n",
            "[CV 5/5; 1/9] START max_depth=3, n_estimators=10................................\n",
            "[CV 5/5; 1/9] END ..............max_depth=3, n_estimators=10; total time=   0.4s\n",
            "[CV 1/5; 2/9] START max_depth=3, n_estimators=50................................\n",
            "[CV 1/5; 2/9] END ..............max_depth=3, n_estimators=50; total time=   1.1s\n",
            "[CV 2/5; 2/9] START max_depth=3, n_estimators=50................................\n",
            "[CV 2/5; 2/9] END ..............max_depth=3, n_estimators=50; total time=   1.2s\n",
            "[CV 3/5; 2/9] START max_depth=3, n_estimators=50................................\n",
            "[CV 3/5; 2/9] END ..............max_depth=3, n_estimators=50; total time=   1.1s\n",
            "[CV 4/5; 2/9] START max_depth=3, n_estimators=50................................\n",
            "[CV 4/5; 2/9] END ..............max_depth=3, n_estimators=50; total time=   1.2s\n",
            "[CV 5/5; 2/9] START max_depth=3, n_estimators=50................................\n",
            "[CV 5/5; 2/9] END ..............max_depth=3, n_estimators=50; total time=   1.2s\n",
            "[CV 1/5; 3/9] START max_depth=3, n_estimators=100...............................\n",
            "[CV 1/5; 3/9] END .............max_depth=3, n_estimators=100; total time=   2.2s\n",
            "[CV 2/5; 3/9] START max_depth=3, n_estimators=100...............................\n",
            "[CV 2/5; 3/9] END .............max_depth=3, n_estimators=100; total time=   2.1s\n",
            "[CV 3/5; 3/9] START max_depth=3, n_estimators=100...............................\n",
            "[CV 3/5; 3/9] END .............max_depth=3, n_estimators=100; total time=   2.1s\n",
            "[CV 4/5; 3/9] START max_depth=3, n_estimators=100...............................\n",
            "[CV 4/5; 3/9] END .............max_depth=3, n_estimators=100; total time=   2.2s\n",
            "[CV 5/5; 3/9] START max_depth=3, n_estimators=100...............................\n",
            "[CV 5/5; 3/9] END .............max_depth=3, n_estimators=100; total time=   2.3s\n",
            "[CV 1/5; 4/9] START max_depth=5, n_estimators=10................................\n",
            "[CV 1/5; 4/9] END ..............max_depth=5, n_estimators=10; total time=   0.4s\n",
            "[CV 2/5; 4/9] START max_depth=5, n_estimators=10................................\n",
            "[CV 2/5; 4/9] END ..............max_depth=5, n_estimators=10; total time=   0.4s\n",
            "[CV 3/5; 4/9] START max_depth=5, n_estimators=10................................\n",
            "[CV 3/5; 4/9] END ..............max_depth=5, n_estimators=10; total time=   0.4s\n",
            "[CV 4/5; 4/9] START max_depth=5, n_estimators=10................................\n",
            "[CV 4/5; 4/9] END ..............max_depth=5, n_estimators=10; total time=   0.4s\n",
            "[CV 5/5; 4/9] START max_depth=5, n_estimators=10................................\n",
            "[CV 5/5; 4/9] END ..............max_depth=5, n_estimators=10; total time=   0.4s\n",
            "[CV 1/5; 5/9] START max_depth=5, n_estimators=50................................\n",
            "[CV 1/5; 5/9] END ..............max_depth=5, n_estimators=50; total time=   1.4s\n",
            "[CV 2/5; 5/9] START max_depth=5, n_estimators=50................................\n",
            "[CV 2/5; 5/9] END ..............max_depth=5, n_estimators=50; total time=   1.5s\n",
            "[CV 3/5; 5/9] START max_depth=5, n_estimators=50................................\n",
            "[CV 3/5; 5/9] END ..............max_depth=5, n_estimators=50; total time=   1.4s\n",
            "[CV 4/5; 5/9] START max_depth=5, n_estimators=50................................\n",
            "[CV 4/5; 5/9] END ..............max_depth=5, n_estimators=50; total time=   1.5s\n",
            "[CV 5/5; 5/9] START max_depth=5, n_estimators=50................................\n",
            "[CV 5/5; 5/9] END ..............max_depth=5, n_estimators=50; total time=   1.5s\n",
            "[CV 1/5; 6/9] START max_depth=5, n_estimators=100...............................\n",
            "[CV 1/5; 6/9] END .............max_depth=5, n_estimators=100; total time=   2.8s\n",
            "[CV 2/5; 6/9] START max_depth=5, n_estimators=100...............................\n",
            "[CV 2/5; 6/9] END .............max_depth=5, n_estimators=100; total time=   2.8s\n",
            "[CV 3/5; 6/9] START max_depth=5, n_estimators=100...............................\n",
            "[CV 3/5; 6/9] END .............max_depth=5, n_estimators=100; total time=   2.7s\n",
            "[CV 4/5; 6/9] START max_depth=5, n_estimators=100...............................\n",
            "[CV 4/5; 6/9] END .............max_depth=5, n_estimators=100; total time=   2.8s\n",
            "[CV 5/5; 6/9] START max_depth=5, n_estimators=100...............................\n",
            "[CV 5/5; 6/9] END .............max_depth=5, n_estimators=100; total time=   2.8s\n",
            "[CV 1/5; 7/9] START max_depth=10, n_estimators=10...............................\n",
            "[CV 1/5; 7/9] END .............max_depth=10, n_estimators=10; total time=   0.5s\n",
            "[CV 2/5; 7/9] START max_depth=10, n_estimators=10...............................\n",
            "[CV 2/5; 7/9] END .............max_depth=10, n_estimators=10; total time=   0.6s\n",
            "[CV 3/5; 7/9] START max_depth=10, n_estimators=10...............................\n",
            "[CV 3/5; 7/9] END .............max_depth=10, n_estimators=10; total time=   0.6s\n",
            "[CV 4/5; 7/9] START max_depth=10, n_estimators=10...............................\n",
            "[CV 4/5; 7/9] END .............max_depth=10, n_estimators=10; total time=   0.6s\n",
            "[CV 5/5; 7/9] START max_depth=10, n_estimators=10...............................\n",
            "[CV 5/5; 7/9] END .............max_depth=10, n_estimators=10; total time=   0.6s\n",
            "[CV 1/5; 8/9] START max_depth=10, n_estimators=50...............................\n",
            "[CV 1/5; 8/9] END .............max_depth=10, n_estimators=50; total time=   2.4s\n",
            "[CV 2/5; 8/9] START max_depth=10, n_estimators=50...............................\n",
            "[CV 2/5; 8/9] END .............max_depth=10, n_estimators=50; total time=   2.5s\n",
            "[CV 3/5; 8/9] START max_depth=10, n_estimators=50...............................\n",
            "[CV 3/5; 8/9] END .............max_depth=10, n_estimators=50; total time=   2.4s\n",
            "[CV 4/5; 8/9] START max_depth=10, n_estimators=50...............................\n",
            "[CV 4/5; 8/9] END .............max_depth=10, n_estimators=50; total time=   2.4s\n",
            "[CV 5/5; 8/9] START max_depth=10, n_estimators=50...............................\n",
            "[CV 5/5; 8/9] END .............max_depth=10, n_estimators=50; total time=   2.4s\n",
            "[CV 1/5; 9/9] START max_depth=10, n_estimators=100..............................\n",
            "[CV 1/5; 9/9] END ............max_depth=10, n_estimators=100; total time=   4.6s\n",
            "[CV 2/5; 9/9] START max_depth=10, n_estimators=100..............................\n",
            "[CV 2/5; 9/9] END ............max_depth=10, n_estimators=100; total time=   4.9s\n",
            "[CV 3/5; 9/9] START max_depth=10, n_estimators=100..............................\n",
            "[CV 3/5; 9/9] END ............max_depth=10, n_estimators=100; total time=   4.6s\n",
            "[CV 4/5; 9/9] START max_depth=10, n_estimators=100..............................\n",
            "[CV 4/5; 9/9] END ............max_depth=10, n_estimators=100; total time=   4.7s\n",
            "[CV 5/5; 9/9] START max_depth=10, n_estimators=100..............................\n",
            "[CV 5/5; 9/9] END ............max_depth=10, n_estimators=100; total time=   5.0s\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5,\n",
              "             estimator=RandomForestClassifier(class_weight='balanced',\n",
              "                                              random_state=42),\n",
              "             n_jobs=-1,\n",
              "             param_grid={'max_depth': [3, 5, 10],\n",
              "                         'n_estimators': [10, 50, 100]},\n",
              "             scoring='f1', verbose=10)"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = RandomForestClassifier(class_weight='balanced', random_state=RANDOM_STATE)\n",
        "param_grid = {\n",
        "'n_estimators': [10, 50, 100],\n",
        "'max_depth': [3, 5, 10]\n",
        "}\n",
        "grid_search = GridSearchCV(model, param_grid, scoring='f1', cv=cv, n_jobs=-1, verbose=10)\n",
        "grid_search.fit(tf_idf_train, target_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-O--NYpc8ep_",
        "outputId": "3b7d3662-57e4-4719-d0c8-56098ff4ad00"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.375350890383831\n"
          ]
        }
      ],
      "source": [
        "forest_score = grid_search.best_score_\n",
        "print(forest_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVzQQm6U8ep_"
      },
      "source": [
        "### CatBoostClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmoPir3q8eqA"
      },
      "source": [
        "Рассчитаем веса классов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UtwLAo4L8eqB"
      },
      "outputs": [],
      "source": [
        "count_negative = (target_train == 0).sum()\n",
        "count_positive = (target_train == 1).sum()\n",
        "scale_pos_weight = count_negative / count_positive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G52ckRcp8eqC",
        "outputId": "72ad0524-f740-42dc-c9f2-2e22828b4d7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5; 1/1] START depth=3, iterations=200.....................................\n",
            "Learning rate set to 0.324686\n",
            "0:\tlearn: 0.6138840\ttotal: 746ms\tremaining: 2m 28s\n",
            "1:\tlearn: 0.5822147\ttotal: 1.38s\tremaining: 2m 16s\n",
            "2:\tlearn: 0.5567401\ttotal: 2.03s\tremaining: 2m 13s\n",
            "3:\tlearn: 0.5397490\ttotal: 2.69s\tremaining: 2m 11s\n",
            "4:\tlearn: 0.5290329\ttotal: 3.34s\tremaining: 2m 10s\n",
            "5:\tlearn: 0.5181888\ttotal: 3.99s\tremaining: 2m 8s\n",
            "6:\tlearn: 0.5063415\ttotal: 4.62s\tremaining: 2m 7s\n",
            "7:\tlearn: 0.4929421\ttotal: 5.26s\tremaining: 2m 6s\n",
            "8:\tlearn: 0.4858585\ttotal: 5.9s\tremaining: 2m 5s\n",
            "9:\tlearn: 0.4807926\ttotal: 6.52s\tremaining: 2m 3s\n",
            "10:\tlearn: 0.4756025\ttotal: 7.18s\tremaining: 2m 3s\n",
            "11:\tlearn: 0.4646971\ttotal: 7.79s\tremaining: 2m 2s\n",
            "12:\tlearn: 0.4584428\ttotal: 8.41s\tremaining: 2m\n",
            "13:\tlearn: 0.4539681\ttotal: 9.01s\tremaining: 1m 59s\n",
            "14:\tlearn: 0.4496637\ttotal: 9.62s\tremaining: 1m 58s\n",
            "15:\tlearn: 0.4443755\ttotal: 10.2s\tremaining: 1m 57s\n",
            "16:\tlearn: 0.4412497\ttotal: 10.8s\tremaining: 1m 56s\n",
            "17:\tlearn: 0.4375606\ttotal: 11.5s\tremaining: 1m 55s\n",
            "18:\tlearn: 0.4342826\ttotal: 12.1s\tremaining: 1m 55s\n",
            "19:\tlearn: 0.4295665\ttotal: 12.7s\tremaining: 1m 54s\n",
            "20:\tlearn: 0.4251350\ttotal: 13.4s\tremaining: 1m 54s\n",
            "21:\tlearn: 0.4204450\ttotal: 14s\tremaining: 1m 53s\n",
            "22:\tlearn: 0.4184611\ttotal: 14.6s\tremaining: 1m 52s\n",
            "23:\tlearn: 0.4157718\ttotal: 15.2s\tremaining: 1m 51s\n",
            "24:\tlearn: 0.4125467\ttotal: 15.9s\tremaining: 1m 51s\n",
            "25:\tlearn: 0.4106552\ttotal: 16.4s\tremaining: 1m 50s\n",
            "26:\tlearn: 0.4089620\ttotal: 17.1s\tremaining: 1m 49s\n",
            "27:\tlearn: 0.4073828\ttotal: 17.7s\tremaining: 1m 48s\n",
            "28:\tlearn: 0.4051597\ttotal: 18.3s\tremaining: 1m 47s\n",
            "29:\tlearn: 0.4030065\ttotal: 18.9s\tremaining: 1m 47s\n",
            "30:\tlearn: 0.4008443\ttotal: 19.5s\tremaining: 1m 46s\n",
            "31:\tlearn: 0.3990474\ttotal: 20.1s\tremaining: 1m 45s\n",
            "32:\tlearn: 0.3959208\ttotal: 20.7s\tremaining: 1m 44s\n",
            "33:\tlearn: 0.3939340\ttotal: 21.3s\tremaining: 1m 44s\n",
            "34:\tlearn: 0.3914642\ttotal: 21.9s\tremaining: 1m 43s\n",
            "35:\tlearn: 0.3887888\ttotal: 22.5s\tremaining: 1m 42s\n",
            "36:\tlearn: 0.3853978\ttotal: 23.2s\tremaining: 1m 42s\n",
            "37:\tlearn: 0.3837783\ttotal: 23.8s\tremaining: 1m 41s\n",
            "38:\tlearn: 0.3806674\ttotal: 24.5s\tremaining: 1m 41s\n",
            "39:\tlearn: 0.3790059\ttotal: 25.1s\tremaining: 1m 40s\n",
            "40:\tlearn: 0.3764556\ttotal: 25.7s\tremaining: 1m 39s\n",
            "41:\tlearn: 0.3747129\ttotal: 26.3s\tremaining: 1m 38s\n",
            "42:\tlearn: 0.3732981\ttotal: 26.9s\tremaining: 1m 38s\n",
            "43:\tlearn: 0.3719105\ttotal: 27.6s\tremaining: 1m 37s\n",
            "44:\tlearn: 0.3693669\ttotal: 28.2s\tremaining: 1m 37s\n",
            "45:\tlearn: 0.3675233\ttotal: 28.8s\tremaining: 1m 36s\n",
            "46:\tlearn: 0.3655300\ttotal: 29.5s\tremaining: 1m 35s\n",
            "47:\tlearn: 0.3640802\ttotal: 30.1s\tremaining: 1m 35s\n",
            "48:\tlearn: 0.3628932\ttotal: 30.7s\tremaining: 1m 34s\n",
            "49:\tlearn: 0.3617288\ttotal: 31.3s\tremaining: 1m 34s\n",
            "50:\tlearn: 0.3605115\ttotal: 32s\tremaining: 1m 33s\n",
            "51:\tlearn: 0.3590231\ttotal: 32.6s\tremaining: 1m 32s\n",
            "52:\tlearn: 0.3578499\ttotal: 33.2s\tremaining: 1m 32s\n",
            "53:\tlearn: 0.3544475\ttotal: 33.8s\tremaining: 1m 31s\n",
            "54:\tlearn: 0.3532087\ttotal: 34.5s\tremaining: 1m 30s\n",
            "55:\tlearn: 0.3518227\ttotal: 35.1s\tremaining: 1m 30s\n",
            "56:\tlearn: 0.3506873\ttotal: 35.7s\tremaining: 1m 29s\n",
            "57:\tlearn: 0.3494740\ttotal: 36.3s\tremaining: 1m 28s\n",
            "58:\tlearn: 0.3483252\ttotal: 37s\tremaining: 1m 28s\n",
            "59:\tlearn: 0.3472273\ttotal: 37.5s\tremaining: 1m 27s\n",
            "60:\tlearn: 0.3462143\ttotal: 38.1s\tremaining: 1m 26s\n",
            "61:\tlearn: 0.3451741\ttotal: 38.7s\tremaining: 1m 26s\n",
            "62:\tlearn: 0.3438405\ttotal: 39.4s\tremaining: 1m 25s\n",
            "63:\tlearn: 0.3428358\ttotal: 40s\tremaining: 1m 24s\n",
            "64:\tlearn: 0.3416518\ttotal: 40.5s\tremaining: 1m 24s\n",
            "65:\tlearn: 0.3406441\ttotal: 41.2s\tremaining: 1m 23s\n",
            "66:\tlearn: 0.3396241\ttotal: 41.8s\tremaining: 1m 22s\n",
            "67:\tlearn: 0.3388078\ttotal: 42.4s\tremaining: 1m 22s\n",
            "68:\tlearn: 0.3376613\ttotal: 43s\tremaining: 1m 21s\n",
            "69:\tlearn: 0.3363647\ttotal: 43.6s\tremaining: 1m 20s\n",
            "70:\tlearn: 0.3348882\ttotal: 44.2s\tremaining: 1m 20s\n",
            "71:\tlearn: 0.3329979\ttotal: 44.8s\tremaining: 1m 19s\n",
            "72:\tlearn: 0.3321770\ttotal: 45.4s\tremaining: 1m 18s\n",
            "73:\tlearn: 0.3311859\ttotal: 46s\tremaining: 1m 18s\n",
            "74:\tlearn: 0.3304493\ttotal: 46.6s\tremaining: 1m 17s\n",
            "75:\tlearn: 0.3295579\ttotal: 47.1s\tremaining: 1m 16s\n",
            "76:\tlearn: 0.3284973\ttotal: 47.7s\tremaining: 1m 16s\n",
            "77:\tlearn: 0.3276877\ttotal: 48.3s\tremaining: 1m 15s\n",
            "78:\tlearn: 0.3262376\ttotal: 48.9s\tremaining: 1m 14s\n",
            "79:\tlearn: 0.3254024\ttotal: 49.5s\tremaining: 1m 14s\n",
            "80:\tlearn: 0.3246470\ttotal: 50.1s\tremaining: 1m 13s\n",
            "81:\tlearn: 0.3238658\ttotal: 50.6s\tremaining: 1m 12s\n",
            "82:\tlearn: 0.3229792\ttotal: 51.3s\tremaining: 1m 12s\n",
            "83:\tlearn: 0.3221367\ttotal: 51.8s\tremaining: 1m 11s\n",
            "84:\tlearn: 0.3206935\ttotal: 52.4s\tremaining: 1m 10s\n",
            "85:\tlearn: 0.3197498\ttotal: 53.1s\tremaining: 1m 10s\n",
            "86:\tlearn: 0.3189831\ttotal: 53.6s\tremaining: 1m 9s\n",
            "87:\tlearn: 0.3179120\ttotal: 54.3s\tremaining: 1m 9s\n",
            "88:\tlearn: 0.3171091\ttotal: 54.9s\tremaining: 1m 8s\n",
            "89:\tlearn: 0.3158446\ttotal: 55.5s\tremaining: 1m 7s\n",
            "90:\tlearn: 0.3151144\ttotal: 56.1s\tremaining: 1m 7s\n",
            "91:\tlearn: 0.3144147\ttotal: 56.7s\tremaining: 1m 6s\n",
            "92:\tlearn: 0.3136058\ttotal: 57.3s\tremaining: 1m 5s\n",
            "93:\tlearn: 0.3127870\ttotal: 57.9s\tremaining: 1m 5s\n",
            "94:\tlearn: 0.3119354\ttotal: 58.5s\tremaining: 1m 4s\n",
            "95:\tlearn: 0.3113056\ttotal: 59s\tremaining: 1m 3s\n",
            "96:\tlearn: 0.3104483\ttotal: 59.7s\tremaining: 1m 3s\n",
            "97:\tlearn: 0.3099510\ttotal: 1m\tremaining: 1m 2s\n",
            "98:\tlearn: 0.3092297\ttotal: 1m\tremaining: 1m 2s\n",
            "99:\tlearn: 0.3085524\ttotal: 1m 1s\tremaining: 1m 1s\n",
            "100:\tlearn: 0.3079498\ttotal: 1m 2s\tremaining: 1m\n",
            "101:\tlearn: 0.3071026\ttotal: 1m 2s\tremaining: 1m\n",
            "102:\tlearn: 0.3063232\ttotal: 1m 3s\tremaining: 59.6s\n",
            "103:\tlearn: 0.3058335\ttotal: 1m 3s\tremaining: 59s\n",
            "104:\tlearn: 0.3053254\ttotal: 1m 4s\tremaining: 58.3s\n",
            "105:\tlearn: 0.3047530\ttotal: 1m 5s\tremaining: 57.7s\n",
            "106:\tlearn: 0.3042242\ttotal: 1m 5s\tremaining: 57s\n",
            "107:\tlearn: 0.3033279\ttotal: 1m 6s\tremaining: 56.4s\n",
            "108:\tlearn: 0.3025933\ttotal: 1m 6s\tremaining: 55.8s\n",
            "109:\tlearn: 0.3020444\ttotal: 1m 7s\tremaining: 55.1s\n",
            "110:\tlearn: 0.3015724\ttotal: 1m 7s\tremaining: 54.5s\n",
            "111:\tlearn: 0.3009220\ttotal: 1m 8s\tremaining: 53.8s\n",
            "112:\tlearn: 0.3003091\ttotal: 1m 9s\tremaining: 53.2s\n",
            "113:\tlearn: 0.2997278\ttotal: 1m 9s\tremaining: 52.6s\n",
            "114:\tlearn: 0.2991999\ttotal: 1m 10s\tremaining: 52s\n",
            "115:\tlearn: 0.2985903\ttotal: 1m 10s\tremaining: 51.4s\n",
            "116:\tlearn: 0.2981985\ttotal: 1m 11s\tremaining: 50.7s\n",
            "117:\tlearn: 0.2975562\ttotal: 1m 12s\tremaining: 50.1s\n",
            "118:\tlearn: 0.2970887\ttotal: 1m 12s\tremaining: 49.5s\n",
            "119:\tlearn: 0.2958914\ttotal: 1m 13s\tremaining: 48.9s\n",
            "120:\tlearn: 0.2954946\ttotal: 1m 13s\tremaining: 48.3s\n",
            "121:\tlearn: 0.2950379\ttotal: 1m 14s\tremaining: 47.6s\n",
            "122:\tlearn: 0.2944795\ttotal: 1m 15s\tremaining: 47s\n",
            "123:\tlearn: 0.2939339\ttotal: 1m 15s\tremaining: 46.4s\n",
            "124:\tlearn: 0.2933953\ttotal: 1m 16s\tremaining: 45.8s\n",
            "125:\tlearn: 0.2928203\ttotal: 1m 16s\tremaining: 45.2s\n",
            "126:\tlearn: 0.2921883\ttotal: 1m 17s\tremaining: 44.6s\n",
            "127:\tlearn: 0.2913486\ttotal: 1m 18s\tremaining: 43.9s\n",
            "128:\tlearn: 0.2902037\ttotal: 1m 18s\tremaining: 43.3s\n",
            "129:\tlearn: 0.2898615\ttotal: 1m 19s\tremaining: 42.7s\n",
            "130:\tlearn: 0.2895289\ttotal: 1m 19s\tremaining: 42.1s\n",
            "131:\tlearn: 0.2890293\ttotal: 1m 20s\tremaining: 41.4s\n",
            "132:\tlearn: 0.2886342\ttotal: 1m 21s\tremaining: 40.8s\n",
            "133:\tlearn: 0.2880703\ttotal: 1m 21s\tremaining: 40.2s\n",
            "134:\tlearn: 0.2876468\ttotal: 1m 22s\tremaining: 39.6s\n",
            "135:\tlearn: 0.2871219\ttotal: 1m 22s\tremaining: 39s\n",
            "136:\tlearn: 0.2868163\ttotal: 1m 23s\tremaining: 38.4s\n",
            "137:\tlearn: 0.2863014\ttotal: 1m 24s\tremaining: 37.8s\n",
            "138:\tlearn: 0.2859232\ttotal: 1m 24s\tremaining: 37.1s\n",
            "139:\tlearn: 0.2854542\ttotal: 1m 25s\tremaining: 36.5s\n",
            "140:\tlearn: 0.2850028\ttotal: 1m 25s\tremaining: 35.9s\n",
            "141:\tlearn: 0.2836231\ttotal: 1m 26s\tremaining: 35.3s\n",
            "142:\tlearn: 0.2833168\ttotal: 1m 26s\tremaining: 34.7s\n",
            "143:\tlearn: 0.2827714\ttotal: 1m 27s\tremaining: 34.1s\n",
            "144:\tlearn: 0.2822082\ttotal: 1m 28s\tremaining: 33.5s\n",
            "145:\tlearn: 0.2818538\ttotal: 1m 28s\tremaining: 32.8s\n",
            "146:\tlearn: 0.2813306\ttotal: 1m 29s\tremaining: 32.2s\n",
            "147:\tlearn: 0.2809745\ttotal: 1m 29s\tremaining: 31.6s\n",
            "148:\tlearn: 0.2805038\ttotal: 1m 30s\tremaining: 31s\n",
            "149:\tlearn: 0.2801533\ttotal: 1m 31s\tremaining: 30.4s\n",
            "150:\tlearn: 0.2796524\ttotal: 1m 31s\tremaining: 29.8s\n",
            "151:\tlearn: 0.2791577\ttotal: 1m 32s\tremaining: 29.2s\n",
            "152:\tlearn: 0.2786933\ttotal: 1m 32s\tremaining: 28.6s\n",
            "153:\tlearn: 0.2784107\ttotal: 1m 33s\tremaining: 27.9s\n",
            "154:\tlearn: 0.2780171\ttotal: 1m 34s\tremaining: 27.3s\n",
            "155:\tlearn: 0.2772536\ttotal: 1m 34s\tremaining: 26.7s\n",
            "156:\tlearn: 0.2765521\ttotal: 1m 35s\tremaining: 26.1s\n",
            "157:\tlearn: 0.2761519\ttotal: 1m 35s\tremaining: 25.5s\n",
            "158:\tlearn: 0.2754297\ttotal: 1m 36s\tremaining: 24.9s\n",
            "159:\tlearn: 0.2751064\ttotal: 1m 37s\tremaining: 24.3s\n",
            "160:\tlearn: 0.2747120\ttotal: 1m 37s\tremaining: 23.6s\n",
            "161:\tlearn: 0.2742758\ttotal: 1m 38s\tremaining: 23s\n",
            "162:\tlearn: 0.2739552\ttotal: 1m 38s\tremaining: 22.4s\n",
            "163:\tlearn: 0.2735481\ttotal: 1m 39s\tremaining: 21.8s\n",
            "164:\tlearn: 0.2730829\ttotal: 1m 39s\tremaining: 21.2s\n",
            "165:\tlearn: 0.2726487\ttotal: 1m 40s\tremaining: 20.6s\n",
            "166:\tlearn: 0.2722677\ttotal: 1m 41s\tremaining: 20s\n",
            "167:\tlearn: 0.2718907\ttotal: 1m 41s\tremaining: 19.4s\n",
            "168:\tlearn: 0.2714783\ttotal: 1m 42s\tremaining: 18.8s\n",
            "169:\tlearn: 0.2709790\ttotal: 1m 42s\tremaining: 18.2s\n",
            "170:\tlearn: 0.2705766\ttotal: 1m 43s\tremaining: 17.6s\n",
            "171:\tlearn: 0.2700701\ttotal: 1m 44s\tremaining: 16.9s\n",
            "172:\tlearn: 0.2696659\ttotal: 1m 44s\tremaining: 16.3s\n",
            "173:\tlearn: 0.2694123\ttotal: 1m 45s\tremaining: 15.7s\n",
            "174:\tlearn: 0.2691445\ttotal: 1m 45s\tremaining: 15.1s\n",
            "175:\tlearn: 0.2686677\ttotal: 1m 46s\tremaining: 14.5s\n",
            "176:\tlearn: 0.2683358\ttotal: 1m 46s\tremaining: 13.9s\n",
            "177:\tlearn: 0.2679370\ttotal: 1m 47s\tremaining: 13.3s\n",
            "178:\tlearn: 0.2675663\ttotal: 1m 48s\tremaining: 12.7s\n",
            "179:\tlearn: 0.2671472\ttotal: 1m 48s\tremaining: 12.1s\n",
            "180:\tlearn: 0.2668616\ttotal: 1m 49s\tremaining: 11.5s\n",
            "181:\tlearn: 0.2665292\ttotal: 1m 49s\tremaining: 10.9s\n",
            "182:\tlearn: 0.2662157\ttotal: 1m 50s\tremaining: 10.3s\n",
            "183:\tlearn: 0.2658730\ttotal: 1m 50s\tremaining: 9.65s\n",
            "184:\tlearn: 0.2655399\ttotal: 1m 51s\tremaining: 9.04s\n",
            "185:\tlearn: 0.2652092\ttotal: 1m 52s\tremaining: 8.44s\n",
            "186:\tlearn: 0.2647928\ttotal: 1m 52s\tremaining: 7.83s\n",
            "187:\tlearn: 0.2644271\ttotal: 1m 53s\tremaining: 7.23s\n",
            "188:\tlearn: 0.2640934\ttotal: 1m 53s\tremaining: 6.63s\n",
            "189:\tlearn: 0.2636179\ttotal: 1m 54s\tremaining: 6.02s\n",
            "190:\tlearn: 0.2633176\ttotal: 1m 54s\tremaining: 5.42s\n",
            "191:\tlearn: 0.2629437\ttotal: 1m 55s\tremaining: 4.82s\n",
            "192:\tlearn: 0.2625849\ttotal: 1m 56s\tremaining: 4.21s\n",
            "193:\tlearn: 0.2621753\ttotal: 1m 56s\tremaining: 3.61s\n",
            "194:\tlearn: 0.2618413\ttotal: 1m 57s\tremaining: 3.01s\n",
            "195:\tlearn: 0.2615651\ttotal: 1m 57s\tremaining: 2.4s\n",
            "196:\tlearn: 0.2613200\ttotal: 1m 58s\tremaining: 1.8s\n",
            "197:\tlearn: 0.2610868\ttotal: 1m 58s\tremaining: 1.2s\n",
            "198:\tlearn: 0.2607408\ttotal: 1m 59s\tremaining: 601ms\n",
            "199:\tlearn: 0.2605689\ttotal: 2m\tremaining: 0us\n",
            "[CV 1/5; 1/1] END ...................depth=3, iterations=200; total time= 2.2min\n",
            "[CV 2/5; 1/1] START depth=3, iterations=200.....................................\n",
            "Learning rate set to 0.324686\n",
            "0:\tlearn: 0.6135455\ttotal: 737ms\tremaining: 2m 26s\n",
            "1:\tlearn: 0.5790371\ttotal: 1.37s\tremaining: 2m 15s\n",
            "2:\tlearn: 0.5567037\ttotal: 2.02s\tremaining: 2m 13s\n",
            "3:\tlearn: 0.5372310\ttotal: 2.68s\tremaining: 2m 11s\n",
            "4:\tlearn: 0.5276638\ttotal: 3.32s\tremaining: 2m 9s\n",
            "5:\tlearn: 0.5138512\ttotal: 4s\tremaining: 2m 9s\n",
            "6:\tlearn: 0.5057418\ttotal: 4.63s\tremaining: 2m 7s\n",
            "7:\tlearn: 0.4980192\ttotal: 5.27s\tremaining: 2m 6s\n",
            "8:\tlearn: 0.4873768\ttotal: 5.9s\tremaining: 2m 5s\n",
            "9:\tlearn: 0.4820902\ttotal: 6.53s\tremaining: 2m 4s\n",
            "10:\tlearn: 0.4735934\ttotal: 7.15s\tremaining: 2m 2s\n",
            "11:\tlearn: 0.4660207\ttotal: 7.75s\tremaining: 2m 1s\n",
            "12:\tlearn: 0.4590804\ttotal: 8.39s\tremaining: 2m\n",
            "13:\tlearn: 0.4554622\ttotal: 9.03s\tremaining: 1m 59s\n",
            "14:\tlearn: 0.4522513\ttotal: 9.69s\tremaining: 1m 59s\n",
            "15:\tlearn: 0.4470847\ttotal: 10.3s\tremaining: 1m 58s\n",
            "16:\tlearn: 0.4439497\ttotal: 11s\tremaining: 1m 58s\n",
            "17:\tlearn: 0.4409386\ttotal: 11.7s\tremaining: 1m 57s\n",
            "18:\tlearn: 0.4358618\ttotal: 12.3s\tremaining: 1m 57s\n",
            "19:\tlearn: 0.4331940\ttotal: 13s\tremaining: 1m 56s\n",
            "20:\tlearn: 0.4303261\ttotal: 13.6s\tremaining: 1m 56s\n",
            "21:\tlearn: 0.4286818\ttotal: 14.3s\tremaining: 1m 55s\n",
            "22:\tlearn: 0.4254978\ttotal: 14.9s\tremaining: 1m 54s\n",
            "23:\tlearn: 0.4222368\ttotal: 15.6s\tremaining: 1m 54s\n",
            "24:\tlearn: 0.4184752\ttotal: 16.2s\tremaining: 1m 53s\n",
            "25:\tlearn: 0.4154281\ttotal: 16.9s\tremaining: 1m 53s\n",
            "26:\tlearn: 0.4121357\ttotal: 17.6s\tremaining: 1m 52s\n",
            "27:\tlearn: 0.4095171\ttotal: 18.2s\tremaining: 1m 51s\n",
            "28:\tlearn: 0.4056489\ttotal: 18.8s\tremaining: 1m 51s\n",
            "29:\tlearn: 0.4041759\ttotal: 19.5s\tremaining: 1m 50s\n",
            "30:\tlearn: 0.4022487\ttotal: 20.1s\tremaining: 1m 49s\n",
            "31:\tlearn: 0.4003820\ttotal: 20.8s\tremaining: 1m 48s\n",
            "32:\tlearn: 0.3987417\ttotal: 21.4s\tremaining: 1m 48s\n",
            "33:\tlearn: 0.3967877\ttotal: 22s\tremaining: 1m 47s\n",
            "34:\tlearn: 0.3951055\ttotal: 22.7s\tremaining: 1m 46s\n",
            "35:\tlearn: 0.3915415\ttotal: 23.3s\tremaining: 1m 46s\n",
            "36:\tlearn: 0.3895113\ttotal: 24s\tremaining: 1m 45s\n",
            "37:\tlearn: 0.3855017\ttotal: 24.6s\tremaining: 1m 44s\n",
            "38:\tlearn: 0.3835701\ttotal: 25.3s\tremaining: 1m 44s\n",
            "39:\tlearn: 0.3818333\ttotal: 25.9s\tremaining: 1m 43s\n",
            "40:\tlearn: 0.3802104\ttotal: 26.6s\tremaining: 1m 43s\n",
            "41:\tlearn: 0.3786578\ttotal: 27.2s\tremaining: 1m 42s\n",
            "42:\tlearn: 0.3761703\ttotal: 27.9s\tremaining: 1m 41s\n",
            "43:\tlearn: 0.3746482\ttotal: 28.5s\tremaining: 1m 41s\n",
            "44:\tlearn: 0.3730649\ttotal: 29.1s\tremaining: 1m 40s\n",
            "45:\tlearn: 0.3711353\ttotal: 29.7s\tremaining: 1m 39s\n",
            "46:\tlearn: 0.3695671\ttotal: 30.4s\tremaining: 1m 38s\n",
            "47:\tlearn: 0.3679909\ttotal: 31s\tremaining: 1m 38s\n",
            "48:\tlearn: 0.3667273\ttotal: 31.7s\tremaining: 1m 37s\n",
            "49:\tlearn: 0.3654238\ttotal: 32.3s\tremaining: 1m 36s\n",
            "50:\tlearn: 0.3619362\ttotal: 33s\tremaining: 1m 36s\n",
            "51:\tlearn: 0.3602639\ttotal: 33.6s\tremaining: 1m 35s\n",
            "52:\tlearn: 0.3587231\ttotal: 34.2s\tremaining: 1m 34s\n",
            "53:\tlearn: 0.3575554\ttotal: 34.8s\tremaining: 1m 34s\n",
            "54:\tlearn: 0.3550746\ttotal: 35.5s\tremaining: 1m 33s\n",
            "55:\tlearn: 0.3533353\ttotal: 36.1s\tremaining: 1m 32s\n",
            "56:\tlearn: 0.3519108\ttotal: 36.7s\tremaining: 1m 32s\n",
            "57:\tlearn: 0.3506683\ttotal: 37.4s\tremaining: 1m 31s\n",
            "58:\tlearn: 0.3494329\ttotal: 38s\tremaining: 1m 30s\n",
            "59:\tlearn: 0.3481511\ttotal: 38.6s\tremaining: 1m 30s\n",
            "60:\tlearn: 0.3470278\ttotal: 39.3s\tremaining: 1m 29s\n",
            "61:\tlearn: 0.3460602\ttotal: 39.9s\tremaining: 1m 28s\n",
            "62:\tlearn: 0.3451072\ttotal: 40.5s\tremaining: 1m 28s\n",
            "63:\tlearn: 0.3441097\ttotal: 41.1s\tremaining: 1m 27s\n",
            "64:\tlearn: 0.3429404\ttotal: 41.7s\tremaining: 1m 26s\n",
            "65:\tlearn: 0.3420224\ttotal: 42.4s\tremaining: 1m 26s\n",
            "66:\tlearn: 0.3411310\ttotal: 43.1s\tremaining: 1m 25s\n",
            "67:\tlearn: 0.3403400\ttotal: 43.7s\tremaining: 1m 24s\n",
            "68:\tlearn: 0.3390359\ttotal: 44.3s\tremaining: 1m 24s\n",
            "69:\tlearn: 0.3380681\ttotal: 45s\tremaining: 1m 23s\n",
            "70:\tlearn: 0.3372302\ttotal: 45.6s\tremaining: 1m 22s\n",
            "71:\tlearn: 0.3362697\ttotal: 46.2s\tremaining: 1m 22s\n",
            "72:\tlearn: 0.3352545\ttotal: 46.8s\tremaining: 1m 21s\n",
            "73:\tlearn: 0.3325764\ttotal: 47.5s\tremaining: 1m 20s\n",
            "74:\tlearn: 0.3315065\ttotal: 48.1s\tremaining: 1m 20s\n",
            "75:\tlearn: 0.3306273\ttotal: 48.7s\tremaining: 1m 19s\n",
            "76:\tlearn: 0.3298013\ttotal: 49.3s\tremaining: 1m 18s\n",
            "77:\tlearn: 0.3291059\ttotal: 50s\tremaining: 1m 18s\n",
            "78:\tlearn: 0.3282315\ttotal: 50.6s\tremaining: 1m 17s\n",
            "79:\tlearn: 0.3265614\ttotal: 51.3s\tremaining: 1m 16s\n",
            "80:\tlearn: 0.3257775\ttotal: 51.9s\tremaining: 1m 16s\n",
            "81:\tlearn: 0.3241720\ttotal: 52.5s\tremaining: 1m 15s\n",
            "82:\tlearn: 0.3234243\ttotal: 53.1s\tremaining: 1m 14s\n",
            "83:\tlearn: 0.3226475\ttotal: 53.7s\tremaining: 1m 14s\n",
            "84:\tlearn: 0.3219944\ttotal: 54.3s\tremaining: 1m 13s\n",
            "85:\tlearn: 0.3212900\ttotal: 55s\tremaining: 1m 12s\n",
            "86:\tlearn: 0.3204799\ttotal: 55.5s\tremaining: 1m 12s\n",
            "87:\tlearn: 0.3191324\ttotal: 56.1s\tremaining: 1m 11s\n",
            "88:\tlearn: 0.3185290\ttotal: 56.7s\tremaining: 1m 10s\n",
            "89:\tlearn: 0.3176407\ttotal: 57.3s\tremaining: 1m 9s\n",
            "90:\tlearn: 0.3170146\ttotal: 57.8s\tremaining: 1m 9s\n",
            "91:\tlearn: 0.3162872\ttotal: 58.4s\tremaining: 1m 8s\n",
            "92:\tlearn: 0.3155293\ttotal: 59s\tremaining: 1m 7s\n",
            "93:\tlearn: 0.3148751\ttotal: 59.6s\tremaining: 1m 7s\n",
            "94:\tlearn: 0.3142183\ttotal: 1m\tremaining: 1m 6s\n",
            "95:\tlearn: 0.3133135\ttotal: 1m\tremaining: 1m 5s\n",
            "96:\tlearn: 0.3125874\ttotal: 1m 1s\tremaining: 1m 5s\n",
            "97:\tlearn: 0.3119651\ttotal: 1m 2s\tremaining: 1m 4s\n",
            "98:\tlearn: 0.3112020\ttotal: 1m 2s\tremaining: 1m 3s\n",
            "99:\tlearn: 0.3107418\ttotal: 1m 3s\tremaining: 1m 3s\n",
            "100:\tlearn: 0.3098231\ttotal: 1m 3s\tremaining: 1m 2s\n",
            "101:\tlearn: 0.3083809\ttotal: 1m 4s\tremaining: 1m 1s\n",
            "102:\tlearn: 0.3078067\ttotal: 1m 5s\tremaining: 1m 1s\n",
            "103:\tlearn: 0.3072853\ttotal: 1m 5s\tremaining: 1m\n",
            "104:\tlearn: 0.3067639\ttotal: 1m 6s\tremaining: 59.9s\n",
            "105:\tlearn: 0.3061301\ttotal: 1m 6s\tremaining: 59.2s\n",
            "106:\tlearn: 0.3056289\ttotal: 1m 7s\tremaining: 58.6s\n",
            "107:\tlearn: 0.3048307\ttotal: 1m 8s\tremaining: 58s\n",
            "108:\tlearn: 0.3041560\ttotal: 1m 8s\tremaining: 57.3s\n",
            "109:\tlearn: 0.3036957\ttotal: 1m 9s\tremaining: 56.7s\n",
            "110:\tlearn: 0.3029614\ttotal: 1m 9s\tremaining: 56s\n",
            "111:\tlearn: 0.3022664\ttotal: 1m 10s\tremaining: 55.3s\n",
            "112:\tlearn: 0.3009254\ttotal: 1m 11s\tremaining: 54.7s\n",
            "113:\tlearn: 0.3004146\ttotal: 1m 11s\tremaining: 54s\n",
            "114:\tlearn: 0.2989734\ttotal: 1m 12s\tremaining: 53.4s\n",
            "115:\tlearn: 0.2982814\ttotal: 1m 12s\tremaining: 52.7s\n",
            "116:\tlearn: 0.2978586\ttotal: 1m 13s\tremaining: 52s\n",
            "117:\tlearn: 0.2970602\ttotal: 1m 13s\tremaining: 51.4s\n",
            "118:\tlearn: 0.2964039\ttotal: 1m 14s\tremaining: 50.7s\n",
            "119:\tlearn: 0.2958358\ttotal: 1m 15s\tremaining: 50s\n",
            "120:\tlearn: 0.2954137\ttotal: 1m 15s\tremaining: 49.4s\n",
            "121:\tlearn: 0.2944909\ttotal: 1m 16s\tremaining: 48.7s\n",
            "122:\tlearn: 0.2938080\ttotal: 1m 16s\tremaining: 48.1s\n",
            "123:\tlearn: 0.2933009\ttotal: 1m 17s\tremaining: 47.4s\n",
            "124:\tlearn: 0.2922755\ttotal: 1m 17s\tremaining: 46.8s\n",
            "125:\tlearn: 0.2919018\ttotal: 1m 18s\tremaining: 46.1s\n",
            "126:\tlearn: 0.2914974\ttotal: 1m 19s\tremaining: 45.5s\n",
            "127:\tlearn: 0.2909541\ttotal: 1m 19s\tremaining: 44.9s\n",
            "128:\tlearn: 0.2905819\ttotal: 1m 20s\tremaining: 44.2s\n",
            "129:\tlearn: 0.2900855\ttotal: 1m 20s\tremaining: 43.6s\n",
            "130:\tlearn: 0.2896433\ttotal: 1m 21s\tremaining: 43s\n",
            "131:\tlearn: 0.2891124\ttotal: 1m 22s\tremaining: 42.3s\n",
            "132:\tlearn: 0.2885760\ttotal: 1m 22s\tremaining: 41.7s\n",
            "133:\tlearn: 0.2879170\ttotal: 1m 23s\tremaining: 41.1s\n",
            "134:\tlearn: 0.2873318\ttotal: 1m 23s\tremaining: 40.4s\n",
            "135:\tlearn: 0.2867952\ttotal: 1m 24s\tremaining: 39.8s\n",
            "136:\tlearn: 0.2862924\ttotal: 1m 25s\tremaining: 39.2s\n",
            "137:\tlearn: 0.2858064\ttotal: 1m 25s\tremaining: 38.5s\n",
            "138:\tlearn: 0.2852881\ttotal: 1m 26s\tremaining: 37.9s\n",
            "139:\tlearn: 0.2847899\ttotal: 1m 26s\tremaining: 37.3s\n",
            "140:\tlearn: 0.2842082\ttotal: 1m 27s\tremaining: 36.6s\n",
            "141:\tlearn: 0.2835631\ttotal: 1m 28s\tremaining: 36s\n",
            "142:\tlearn: 0.2832672\ttotal: 1m 28s\tremaining: 35.4s\n",
            "143:\tlearn: 0.2827090\ttotal: 1m 29s\tremaining: 34.8s\n",
            "144:\tlearn: 0.2822679\ttotal: 1m 29s\tremaining: 34.1s\n",
            "145:\tlearn: 0.2812206\ttotal: 1m 30s\tremaining: 33.5s\n",
            "146:\tlearn: 0.2807860\ttotal: 1m 31s\tremaining: 32.9s\n",
            "147:\tlearn: 0.2803999\ttotal: 1m 31s\tremaining: 32.2s\n",
            "148:\tlearn: 0.2800584\ttotal: 1m 32s\tremaining: 31.6s\n",
            "149:\tlearn: 0.2796589\ttotal: 1m 32s\tremaining: 31s\n",
            "150:\tlearn: 0.2791744\ttotal: 1m 33s\tremaining: 30.4s\n",
            "151:\tlearn: 0.2784590\ttotal: 1m 34s\tremaining: 29.7s\n",
            "152:\tlearn: 0.2778961\ttotal: 1m 34s\tremaining: 29.1s\n",
            "153:\tlearn: 0.2775513\ttotal: 1m 35s\tremaining: 28.5s\n",
            "154:\tlearn: 0.2770446\ttotal: 1m 35s\tremaining: 27.9s\n",
            "155:\tlearn: 0.2765760\ttotal: 1m 36s\tremaining: 27.2s\n",
            "156:\tlearn: 0.2762328\ttotal: 1m 37s\tremaining: 26.6s\n",
            "157:\tlearn: 0.2759362\ttotal: 1m 37s\tremaining: 26s\n",
            "158:\tlearn: 0.2753625\ttotal: 1m 38s\tremaining: 25.3s\n",
            "159:\tlearn: 0.2749552\ttotal: 1m 38s\tremaining: 24.7s\n",
            "160:\tlearn: 0.2744181\ttotal: 1m 39s\tremaining: 24.1s\n",
            "161:\tlearn: 0.2740008\ttotal: 1m 40s\tremaining: 23.5s\n",
            "162:\tlearn: 0.2736744\ttotal: 1m 40s\tremaining: 22.8s\n",
            "163:\tlearn: 0.2732683\ttotal: 1m 41s\tremaining: 22.2s\n",
            "164:\tlearn: 0.2728689\ttotal: 1m 41s\tremaining: 21.6s\n",
            "165:\tlearn: 0.2724668\ttotal: 1m 42s\tremaining: 21s\n",
            "166:\tlearn: 0.2719862\ttotal: 1m 42s\tremaining: 20.3s\n",
            "167:\tlearn: 0.2715627\ttotal: 1m 43s\tremaining: 19.7s\n",
            "168:\tlearn: 0.2706380\ttotal: 1m 44s\tremaining: 19.1s\n",
            "169:\tlearn: 0.2703243\ttotal: 1m 44s\tremaining: 18.5s\n",
            "170:\tlearn: 0.2700478\ttotal: 1m 45s\tremaining: 17.9s\n",
            "171:\tlearn: 0.2697286\ttotal: 1m 45s\tremaining: 17.2s\n",
            "172:\tlearn: 0.2694459\ttotal: 1m 46s\tremaining: 16.6s\n",
            "173:\tlearn: 0.2691294\ttotal: 1m 47s\tremaining: 16s\n",
            "174:\tlearn: 0.2687272\ttotal: 1m 47s\tremaining: 15.4s\n",
            "175:\tlearn: 0.2684625\ttotal: 1m 48s\tremaining: 14.8s\n",
            "176:\tlearn: 0.2681302\ttotal: 1m 48s\tremaining: 14.1s\n",
            "177:\tlearn: 0.2678077\ttotal: 1m 49s\tremaining: 13.5s\n",
            "178:\tlearn: 0.2675107\ttotal: 1m 49s\tremaining: 12.9s\n",
            "179:\tlearn: 0.2671134\ttotal: 1m 50s\tremaining: 12.3s\n",
            "180:\tlearn: 0.2667877\ttotal: 1m 51s\tremaining: 11.7s\n",
            "181:\tlearn: 0.2663169\ttotal: 1m 51s\tremaining: 11s\n",
            "182:\tlearn: 0.2659983\ttotal: 1m 52s\tremaining: 10.4s\n",
            "183:\tlearn: 0.2657338\ttotal: 1m 52s\tremaining: 9.82s\n",
            "184:\tlearn: 0.2654284\ttotal: 1m 53s\tremaining: 9.2s\n",
            "185:\tlearn: 0.2651918\ttotal: 1m 54s\tremaining: 8.58s\n",
            "186:\tlearn: 0.2648444\ttotal: 1m 54s\tremaining: 7.97s\n",
            "187:\tlearn: 0.2645140\ttotal: 1m 55s\tremaining: 7.36s\n",
            "188:\tlearn: 0.2642322\ttotal: 1m 55s\tremaining: 6.75s\n",
            "189:\tlearn: 0.2639702\ttotal: 1m 56s\tremaining: 6.13s\n",
            "190:\tlearn: 0.2637457\ttotal: 1m 57s\tremaining: 5.51s\n",
            "191:\tlearn: 0.2631985\ttotal: 1m 57s\tremaining: 4.9s\n",
            "192:\tlearn: 0.2629442\ttotal: 1m 58s\tremaining: 4.29s\n",
            "193:\tlearn: 0.2625050\ttotal: 1m 58s\tremaining: 3.67s\n",
            "194:\tlearn: 0.2621232\ttotal: 1m 59s\tremaining: 3.06s\n",
            "195:\tlearn: 0.2619086\ttotal: 2m\tremaining: 2.45s\n",
            "196:\tlearn: 0.2615088\ttotal: 2m\tremaining: 1.84s\n",
            "197:\tlearn: 0.2612597\ttotal: 2m 1s\tremaining: 1.22s\n",
            "198:\tlearn: 0.2606394\ttotal: 2m 1s\tremaining: 612ms\n",
            "199:\tlearn: 0.2603002\ttotal: 2m 2s\tremaining: 0us\n",
            "[CV 2/5; 1/1] END ...................depth=3, iterations=200; total time= 2.2min\n",
            "[CV 3/5; 1/1] START depth=3, iterations=200.....................................\n",
            "Learning rate set to 0.324686\n",
            "0:\tlearn: 0.6121810\ttotal: 804ms\tremaining: 2m 40s\n",
            "1:\tlearn: 0.5777645\ttotal: 1.5s\tremaining: 2m 28s\n",
            "2:\tlearn: 0.5544842\ttotal: 2.18s\tremaining: 2m 23s\n",
            "3:\tlearn: 0.5369761\ttotal: 2.88s\tremaining: 2m 21s\n",
            "4:\tlearn: 0.5273933\ttotal: 3.55s\tremaining: 2m 18s\n",
            "5:\tlearn: 0.5135916\ttotal: 4.28s\tremaining: 2m 18s\n",
            "6:\tlearn: 0.4978893\ttotal: 4.95s\tremaining: 2m 16s\n",
            "7:\tlearn: 0.4896275\ttotal: 5.63s\tremaining: 2m 15s\n",
            "8:\tlearn: 0.4822757\ttotal: 6.27s\tremaining: 2m 13s\n",
            "9:\tlearn: 0.4743068\ttotal: 6.94s\tremaining: 2m 11s\n",
            "10:\tlearn: 0.4652532\ttotal: 7.58s\tremaining: 2m 10s\n",
            "11:\tlearn: 0.4601526\ttotal: 8.25s\tremaining: 2m 9s\n",
            "12:\tlearn: 0.4558976\ttotal: 8.9s\tremaining: 2m 8s\n",
            "13:\tlearn: 0.4512770\ttotal: 9.6s\tremaining: 2m 7s\n",
            "14:\tlearn: 0.4478256\ttotal: 10.3s\tremaining: 2m 7s\n",
            "15:\tlearn: 0.4436006\ttotal: 10.9s\tremaining: 2m 5s\n",
            "16:\tlearn: 0.4397773\ttotal: 11.6s\tremaining: 2m 4s\n",
            "17:\tlearn: 0.4359866\ttotal: 12.2s\tremaining: 2m 3s\n",
            "18:\tlearn: 0.4310528\ttotal: 12.9s\tremaining: 2m 2s\n",
            "19:\tlearn: 0.4279406\ttotal: 13.6s\tremaining: 2m 2s\n",
            "20:\tlearn: 0.4250612\ttotal: 14.3s\tremaining: 2m 1s\n",
            "21:\tlearn: 0.4231827\ttotal: 14.9s\tremaining: 2m\n",
            "22:\tlearn: 0.4190141\ttotal: 15.6s\tremaining: 1m 59s\n",
            "23:\tlearn: 0.4166687\ttotal: 16.3s\tremaining: 1m 59s\n",
            "24:\tlearn: 0.4140218\ttotal: 16.9s\tremaining: 1m 58s\n",
            "25:\tlearn: 0.4117922\ttotal: 17.5s\tremaining: 1m 57s\n",
            "26:\tlearn: 0.4090701\ttotal: 18.2s\tremaining: 1m 56s\n",
            "27:\tlearn: 0.4071740\ttotal: 18.9s\tremaining: 1m 55s\n",
            "28:\tlearn: 0.4028860\ttotal: 19.5s\tremaining: 1m 55s\n",
            "29:\tlearn: 0.4004240\ttotal: 20.2s\tremaining: 1m 54s\n",
            "30:\tlearn: 0.3970913\ttotal: 20.9s\tremaining: 1m 54s\n",
            "31:\tlearn: 0.3954698\ttotal: 21.6s\tremaining: 1m 53s\n",
            "32:\tlearn: 0.3932863\ttotal: 22.2s\tremaining: 1m 52s\n",
            "33:\tlearn: 0.3912916\ttotal: 22.9s\tremaining: 1m 51s\n",
            "34:\tlearn: 0.3895141\ttotal: 23.6s\tremaining: 1m 51s\n",
            "35:\tlearn: 0.3875050\ttotal: 24.2s\tremaining: 1m 50s\n",
            "36:\tlearn: 0.3859937\ttotal: 24.9s\tremaining: 1m 49s\n",
            "37:\tlearn: 0.3841643\ttotal: 25.5s\tremaining: 1m 48s\n",
            "38:\tlearn: 0.3818015\ttotal: 26.2s\tremaining: 1m 48s\n",
            "39:\tlearn: 0.3802374\ttotal: 26.9s\tremaining: 1m 47s\n",
            "40:\tlearn: 0.3786230\ttotal: 27.5s\tremaining: 1m 46s\n",
            "41:\tlearn: 0.3768792\ttotal: 28.2s\tremaining: 1m 45s\n",
            "42:\tlearn: 0.3753103\ttotal: 28.8s\tremaining: 1m 45s\n",
            "43:\tlearn: 0.3730379\ttotal: 29.4s\tremaining: 1m 44s\n",
            "44:\tlearn: 0.3714859\ttotal: 30.1s\tremaining: 1m 43s\n",
            "45:\tlearn: 0.3699669\ttotal: 30.7s\tremaining: 1m 42s\n",
            "46:\tlearn: 0.3682124\ttotal: 31.4s\tremaining: 1m 42s\n",
            "47:\tlearn: 0.3663746\ttotal: 32s\tremaining: 1m 41s\n",
            "48:\tlearn: 0.3647817\ttotal: 32.6s\tremaining: 1m 40s\n",
            "49:\tlearn: 0.3633211\ttotal: 33.3s\tremaining: 1m 39s\n",
            "50:\tlearn: 0.3620490\ttotal: 33.9s\tremaining: 1m 39s\n",
            "51:\tlearn: 0.3592182\ttotal: 34.6s\tremaining: 1m 38s\n",
            "52:\tlearn: 0.3576381\ttotal: 35.2s\tremaining: 1m 37s\n",
            "53:\tlearn: 0.3562550\ttotal: 35.8s\tremaining: 1m 36s\n",
            "54:\tlearn: 0.3549889\ttotal: 36.5s\tremaining: 1m 36s\n",
            "55:\tlearn: 0.3537613\ttotal: 37.1s\tremaining: 1m 35s\n",
            "56:\tlearn: 0.3523196\ttotal: 37.8s\tremaining: 1m 34s\n",
            "57:\tlearn: 0.3511902\ttotal: 38.4s\tremaining: 1m 33s\n",
            "58:\tlearn: 0.3500051\ttotal: 39s\tremaining: 1m 33s\n",
            "59:\tlearn: 0.3485356\ttotal: 39.7s\tremaining: 1m 32s\n",
            "60:\tlearn: 0.3472050\ttotal: 40.3s\tremaining: 1m 31s\n",
            "61:\tlearn: 0.3463085\ttotal: 41s\tremaining: 1m 31s\n",
            "62:\tlearn: 0.3451915\ttotal: 41.6s\tremaining: 1m 30s\n",
            "63:\tlearn: 0.3440835\ttotal: 42.3s\tremaining: 1m 29s\n",
            "64:\tlearn: 0.3430724\ttotal: 42.9s\tremaining: 1m 29s\n",
            "65:\tlearn: 0.3420013\ttotal: 43.6s\tremaining: 1m 28s\n",
            "66:\tlearn: 0.3412674\ttotal: 44.2s\tremaining: 1m 27s\n",
            "67:\tlearn: 0.3404956\ttotal: 44.8s\tremaining: 1m 27s\n",
            "68:\tlearn: 0.3391295\ttotal: 45.4s\tremaining: 1m 26s\n",
            "69:\tlearn: 0.3382450\ttotal: 46.1s\tremaining: 1m 25s\n",
            "70:\tlearn: 0.3375061\ttotal: 46.7s\tremaining: 1m 24s\n",
            "71:\tlearn: 0.3363812\ttotal: 47.3s\tremaining: 1m 24s\n",
            "72:\tlearn: 0.3349099\ttotal: 47.9s\tremaining: 1m 23s\n",
            "73:\tlearn: 0.3341311\ttotal: 48.5s\tremaining: 1m 22s\n",
            "74:\tlearn: 0.3333286\ttotal: 49.1s\tremaining: 1m 21s\n",
            "75:\tlearn: 0.3322817\ttotal: 49.7s\tremaining: 1m 21s\n",
            "76:\tlearn: 0.3309815\ttotal: 50.3s\tremaining: 1m 20s\n",
            "77:\tlearn: 0.3302839\ttotal: 51s\tremaining: 1m 19s\n",
            "78:\tlearn: 0.3294880\ttotal: 51.6s\tremaining: 1m 18s\n",
            "79:\tlearn: 0.3287284\ttotal: 52.1s\tremaining: 1m 18s\n",
            "80:\tlearn: 0.3265103\ttotal: 52.8s\tremaining: 1m 17s\n",
            "81:\tlearn: 0.3245980\ttotal: 53.3s\tremaining: 1m 16s\n",
            "82:\tlearn: 0.3236784\ttotal: 53.9s\tremaining: 1m 16s\n",
            "83:\tlearn: 0.3229140\ttotal: 54.5s\tremaining: 1m 15s\n",
            "84:\tlearn: 0.3222619\ttotal: 55.1s\tremaining: 1m 14s\n",
            "85:\tlearn: 0.3212893\ttotal: 55.6s\tremaining: 1m 13s\n",
            "86:\tlearn: 0.3206135\ttotal: 56.2s\tremaining: 1m 12s\n",
            "87:\tlearn: 0.3198666\ttotal: 56.8s\tremaining: 1m 12s\n",
            "88:\tlearn: 0.3192285\ttotal: 57.4s\tremaining: 1m 11s\n",
            "89:\tlearn: 0.3184813\ttotal: 57.9s\tremaining: 1m 10s\n",
            "90:\tlearn: 0.3173710\ttotal: 58.6s\tremaining: 1m 10s\n",
            "91:\tlearn: 0.3167225\ttotal: 59.2s\tremaining: 1m 9s\n",
            "92:\tlearn: 0.3160265\ttotal: 59.8s\tremaining: 1m 8s\n",
            "93:\tlearn: 0.3152934\ttotal: 1m\tremaining: 1m 8s\n",
            "94:\tlearn: 0.3145079\ttotal: 1m\tremaining: 1m 7s\n",
            "95:\tlearn: 0.3136376\ttotal: 1m 1s\tremaining: 1m 6s\n",
            "96:\tlearn: 0.3127615\ttotal: 1m 2s\tremaining: 1m 6s\n",
            "97:\tlearn: 0.3112239\ttotal: 1m 2s\tremaining: 1m 5s\n",
            "98:\tlearn: 0.3104985\ttotal: 1m 3s\tremaining: 1m 4s\n",
            "99:\tlearn: 0.3098952\ttotal: 1m 4s\tremaining: 1m 4s\n",
            "100:\tlearn: 0.3092946\ttotal: 1m 4s\tremaining: 1m 3s\n",
            "101:\tlearn: 0.3082790\ttotal: 1m 5s\tremaining: 1m 2s\n",
            "102:\tlearn: 0.3076173\ttotal: 1m 5s\tremaining: 1m 2s\n",
            "103:\tlearn: 0.3069739\ttotal: 1m 6s\tremaining: 1m 1s\n",
            "104:\tlearn: 0.3064061\ttotal: 1m 7s\tremaining: 1m\n",
            "105:\tlearn: 0.3047903\ttotal: 1m 7s\tremaining: 59.9s\n",
            "106:\tlearn: 0.3041971\ttotal: 1m 8s\tremaining: 59.2s\n",
            "107:\tlearn: 0.3036982\ttotal: 1m 8s\tremaining: 58.5s\n",
            "108:\tlearn: 0.3030509\ttotal: 1m 9s\tremaining: 57.9s\n",
            "109:\tlearn: 0.3023382\ttotal: 1m 9s\tremaining: 57.2s\n",
            "110:\tlearn: 0.3018309\ttotal: 1m 10s\tremaining: 56.6s\n",
            "111:\tlearn: 0.3011158\ttotal: 1m 11s\tremaining: 55.9s\n",
            "112:\tlearn: 0.2997936\ttotal: 1m 11s\tremaining: 55.3s\n",
            "113:\tlearn: 0.2991878\ttotal: 1m 12s\tremaining: 54.6s\n",
            "114:\tlearn: 0.2984472\ttotal: 1m 13s\tremaining: 54s\n",
            "115:\tlearn: 0.2974048\ttotal: 1m 13s\tremaining: 53.3s\n",
            "116:\tlearn: 0.2968383\ttotal: 1m 14s\tremaining: 52.6s\n",
            "117:\tlearn: 0.2963610\ttotal: 1m 14s\tremaining: 52s\n",
            "118:\tlearn: 0.2958946\ttotal: 1m 15s\tremaining: 51.3s\n",
            "119:\tlearn: 0.2954863\ttotal: 1m 15s\tremaining: 50.6s\n",
            "120:\tlearn: 0.2949826\ttotal: 1m 16s\tremaining: 49.9s\n",
            "121:\tlearn: 0.2943521\ttotal: 1m 17s\tremaining: 49.3s\n",
            "122:\tlearn: 0.2936881\ttotal: 1m 17s\tremaining: 48.6s\n",
            "123:\tlearn: 0.2926295\ttotal: 1m 18s\tremaining: 48s\n",
            "124:\tlearn: 0.2919002\ttotal: 1m 18s\tremaining: 47.4s\n",
            "125:\tlearn: 0.2914631\ttotal: 1m 19s\tremaining: 46.7s\n",
            "126:\tlearn: 0.2908722\ttotal: 1m 20s\tremaining: 46s\n",
            "127:\tlearn: 0.2902365\ttotal: 1m 20s\tremaining: 45.4s\n",
            "128:\tlearn: 0.2895360\ttotal: 1m 21s\tremaining: 44.7s\n",
            "129:\tlearn: 0.2891460\ttotal: 1m 21s\tremaining: 44.1s\n",
            "130:\tlearn: 0.2886287\ttotal: 1m 22s\tremaining: 43.4s\n",
            "131:\tlearn: 0.2881998\ttotal: 1m 23s\tremaining: 42.8s\n",
            "132:\tlearn: 0.2878137\ttotal: 1m 23s\tremaining: 42.1s\n",
            "133:\tlearn: 0.2873310\ttotal: 1m 24s\tremaining: 41.4s\n",
            "134:\tlearn: 0.2869290\ttotal: 1m 24s\tremaining: 40.8s\n",
            "135:\tlearn: 0.2864993\ttotal: 1m 25s\tremaining: 40.1s\n",
            "136:\tlearn: 0.2857202\ttotal: 1m 25s\tremaining: 39.5s\n",
            "137:\tlearn: 0.2852152\ttotal: 1m 26s\tremaining: 38.9s\n",
            "138:\tlearn: 0.2848907\ttotal: 1m 27s\tremaining: 38.2s\n",
            "139:\tlearn: 0.2845156\ttotal: 1m 27s\tremaining: 37.6s\n",
            "140:\tlearn: 0.2839298\ttotal: 1m 28s\tremaining: 36.9s\n",
            "141:\tlearn: 0.2834934\ttotal: 1m 28s\tremaining: 36.3s\n",
            "142:\tlearn: 0.2830646\ttotal: 1m 29s\tremaining: 35.6s\n",
            "143:\tlearn: 0.2824889\ttotal: 1m 30s\tremaining: 35s\n",
            "144:\tlearn: 0.2818445\ttotal: 1m 30s\tremaining: 34.4s\n",
            "145:\tlearn: 0.2813633\ttotal: 1m 31s\tremaining: 33.8s\n",
            "146:\tlearn: 0.2810896\ttotal: 1m 31s\tremaining: 33.1s\n",
            "147:\tlearn: 0.2806500\ttotal: 1m 32s\tremaining: 32.5s\n",
            "148:\tlearn: 0.2799672\ttotal: 1m 33s\tremaining: 31.9s\n",
            "149:\tlearn: 0.2796421\ttotal: 1m 33s\tremaining: 31.2s\n",
            "150:\tlearn: 0.2788274\ttotal: 1m 34s\tremaining: 30.6s\n",
            "151:\tlearn: 0.2784687\ttotal: 1m 34s\tremaining: 30s\n",
            "152:\tlearn: 0.2780358\ttotal: 1m 35s\tremaining: 29.3s\n",
            "153:\tlearn: 0.2776430\ttotal: 1m 35s\tremaining: 28.7s\n",
            "154:\tlearn: 0.2773754\ttotal: 1m 36s\tremaining: 28s\n",
            "155:\tlearn: 0.2769928\ttotal: 1m 37s\tremaining: 27.4s\n",
            "156:\tlearn: 0.2766433\ttotal: 1m 37s\tremaining: 26.8s\n",
            "157:\tlearn: 0.2761835\ttotal: 1m 38s\tremaining: 26.1s\n",
            "158:\tlearn: 0.2758677\ttotal: 1m 38s\tremaining: 25.5s\n",
            "159:\tlearn: 0.2754296\ttotal: 1m 39s\tremaining: 24.9s\n",
            "160:\tlearn: 0.2751225\ttotal: 1m 40s\tremaining: 24.3s\n",
            "161:\tlearn: 0.2747265\ttotal: 1m 40s\tremaining: 23.6s\n",
            "162:\tlearn: 0.2744643\ttotal: 1m 41s\tremaining: 23s\n",
            "163:\tlearn: 0.2739428\ttotal: 1m 41s\tremaining: 22.4s\n",
            "164:\tlearn: 0.2734945\ttotal: 1m 42s\tremaining: 21.7s\n",
            "165:\tlearn: 0.2730652\ttotal: 1m 43s\tremaining: 21.1s\n",
            "166:\tlearn: 0.2727406\ttotal: 1m 43s\tremaining: 20.5s\n",
            "167:\tlearn: 0.2723768\ttotal: 1m 44s\tremaining: 19.9s\n",
            "168:\tlearn: 0.2721047\ttotal: 1m 44s\tremaining: 19.2s\n",
            "169:\tlearn: 0.2717140\ttotal: 1m 45s\tremaining: 18.6s\n",
            "170:\tlearn: 0.2713005\ttotal: 1m 45s\tremaining: 18s\n",
            "171:\tlearn: 0.2707703\ttotal: 1m 46s\tremaining: 17.3s\n",
            "172:\tlearn: 0.2703333\ttotal: 1m 47s\tremaining: 16.7s\n",
            "173:\tlearn: 0.2698800\ttotal: 1m 47s\tremaining: 16.1s\n",
            "174:\tlearn: 0.2696047\ttotal: 1m 48s\tremaining: 15.5s\n",
            "175:\tlearn: 0.2692364\ttotal: 1m 48s\tremaining: 14.8s\n",
            "176:\tlearn: 0.2688517\ttotal: 1m 49s\tremaining: 14.2s\n",
            "177:\tlearn: 0.2686015\ttotal: 1m 50s\tremaining: 13.6s\n",
            "178:\tlearn: 0.2683323\ttotal: 1m 50s\tremaining: 13s\n",
            "179:\tlearn: 0.2680030\ttotal: 1m 51s\tremaining: 12.4s\n",
            "180:\tlearn: 0.2676500\ttotal: 1m 51s\tremaining: 11.7s\n",
            "181:\tlearn: 0.2673199\ttotal: 1m 52s\tremaining: 11.1s\n",
            "182:\tlearn: 0.2670789\ttotal: 1m 52s\tremaining: 10.5s\n",
            "183:\tlearn: 0.2659925\ttotal: 1m 53s\tremaining: 9.87s\n",
            "184:\tlearn: 0.2654756\ttotal: 1m 54s\tremaining: 9.26s\n",
            "185:\tlearn: 0.2651245\ttotal: 1m 54s\tremaining: 8.64s\n",
            "186:\tlearn: 0.2644475\ttotal: 1m 55s\tremaining: 8.02s\n",
            "187:\tlearn: 0.2640318\ttotal: 1m 55s\tremaining: 7.4s\n",
            "188:\tlearn: 0.2637740\ttotal: 1m 56s\tremaining: 6.78s\n",
            "189:\tlearn: 0.2633319\ttotal: 1m 57s\tremaining: 6.16s\n",
            "190:\tlearn: 0.2630271\ttotal: 1m 57s\tremaining: 5.54s\n",
            "191:\tlearn: 0.2625191\ttotal: 1m 58s\tremaining: 4.93s\n",
            "192:\tlearn: 0.2622889\ttotal: 1m 58s\tremaining: 4.31s\n",
            "193:\tlearn: 0.2619627\ttotal: 1m 59s\tremaining: 3.7s\n",
            "194:\tlearn: 0.2615365\ttotal: 2m\tremaining: 3.08s\n",
            "195:\tlearn: 0.2612922\ttotal: 2m\tremaining: 2.46s\n",
            "196:\tlearn: 0.2607732\ttotal: 2m 1s\tremaining: 1.85s\n",
            "197:\tlearn: 0.2603121\ttotal: 2m 1s\tremaining: 1.23s\n",
            "198:\tlearn: 0.2600645\ttotal: 2m 2s\tremaining: 615ms\n",
            "199:\tlearn: 0.2596187\ttotal: 2m 3s\tremaining: 0us\n",
            "[CV 3/5; 1/1] END ...................depth=3, iterations=200; total time= 2.2min\n",
            "[CV 4/5; 1/1] START depth=3, iterations=200.....................................\n",
            "Learning rate set to 0.324687\n",
            "0:\tlearn: 0.6115831\ttotal: 709ms\tremaining: 2m 21s\n",
            "1:\tlearn: 0.5804371\ttotal: 1.34s\tremaining: 2m 13s\n",
            "2:\tlearn: 0.5557068\ttotal: 1.99s\tremaining: 2m 10s\n",
            "3:\tlearn: 0.5391158\ttotal: 2.65s\tremaining: 2m 9s\n",
            "4:\tlearn: 0.5267233\ttotal: 3.36s\tremaining: 2m 11s\n",
            "5:\tlearn: 0.5161874\ttotal: 4.02s\tremaining: 2m 9s\n",
            "6:\tlearn: 0.5054369\ttotal: 4.66s\tremaining: 2m 8s\n",
            "7:\tlearn: 0.4936035\ttotal: 5.31s\tremaining: 2m 7s\n",
            "8:\tlearn: 0.4823149\ttotal: 5.93s\tremaining: 2m 5s\n",
            "9:\tlearn: 0.4776636\ttotal: 6.57s\tremaining: 2m 4s\n",
            "10:\tlearn: 0.4698279\ttotal: 7.21s\tremaining: 2m 3s\n",
            "11:\tlearn: 0.4633712\ttotal: 7.87s\tremaining: 2m 3s\n",
            "12:\tlearn: 0.4591869\ttotal: 8.51s\tremaining: 2m 2s\n",
            "13:\tlearn: 0.4536622\ttotal: 9.14s\tremaining: 2m 1s\n",
            "14:\tlearn: 0.4493293\ttotal: 9.76s\tremaining: 2m\n",
            "15:\tlearn: 0.4445761\ttotal: 10.4s\tremaining: 1m 59s\n",
            "16:\tlearn: 0.4400434\ttotal: 11s\tremaining: 1m 58s\n",
            "17:\tlearn: 0.4370613\ttotal: 11.6s\tremaining: 1m 57s\n",
            "18:\tlearn: 0.4331410\ttotal: 12.3s\tremaining: 1m 56s\n",
            "19:\tlearn: 0.4307310\ttotal: 12.9s\tremaining: 1m 55s\n",
            "20:\tlearn: 0.4276661\ttotal: 13.5s\tremaining: 1m 54s\n",
            "21:\tlearn: 0.4228134\ttotal: 14.1s\tremaining: 1m 54s\n",
            "22:\tlearn: 0.4200089\ttotal: 14.7s\tremaining: 1m 53s\n",
            "23:\tlearn: 0.4170176\ttotal: 15.3s\tremaining: 1m 52s\n",
            "24:\tlearn: 0.4150536\ttotal: 16s\tremaining: 1m 51s\n",
            "25:\tlearn: 0.4130964\ttotal: 16.6s\tremaining: 1m 50s\n",
            "26:\tlearn: 0.4114723\ttotal: 17.2s\tremaining: 1m 50s\n",
            "27:\tlearn: 0.4088820\ttotal: 17.8s\tremaining: 1m 49s\n",
            "28:\tlearn: 0.4070319\ttotal: 18.5s\tremaining: 1m 48s\n",
            "29:\tlearn: 0.4053172\ttotal: 19.1s\tremaining: 1m 48s\n",
            "30:\tlearn: 0.4036456\ttotal: 19.7s\tremaining: 1m 47s\n",
            "31:\tlearn: 0.4020630\ttotal: 20.3s\tremaining: 1m 46s\n",
            "32:\tlearn: 0.4002612\ttotal: 21s\tremaining: 1m 46s\n",
            "33:\tlearn: 0.3970621\ttotal: 21.6s\tremaining: 1m 45s\n",
            "34:\tlearn: 0.3943839\ttotal: 22.2s\tremaining: 1m 44s\n",
            "35:\tlearn: 0.3916186\ttotal: 22.9s\tremaining: 1m 44s\n",
            "36:\tlearn: 0.3897004\ttotal: 23.5s\tremaining: 1m 43s\n",
            "37:\tlearn: 0.3880185\ttotal: 24.1s\tremaining: 1m 42s\n",
            "38:\tlearn: 0.3856237\ttotal: 24.8s\tremaining: 1m 42s\n",
            "39:\tlearn: 0.3824698\ttotal: 25.4s\tremaining: 1m 41s\n",
            "40:\tlearn: 0.3804729\ttotal: 26s\tremaining: 1m 40s\n",
            "41:\tlearn: 0.3789011\ttotal: 26.6s\tremaining: 1m 40s\n",
            "42:\tlearn: 0.3767108\ttotal: 27.2s\tremaining: 1m 39s\n",
            "43:\tlearn: 0.3752835\ttotal: 27.8s\tremaining: 1m 38s\n",
            "44:\tlearn: 0.3730356\ttotal: 28.5s\tremaining: 1m 38s\n",
            "45:\tlearn: 0.3706016\ttotal: 29.1s\tremaining: 1m 37s\n",
            "46:\tlearn: 0.3686974\ttotal: 29.7s\tremaining: 1m 36s\n",
            "47:\tlearn: 0.3670558\ttotal: 30.3s\tremaining: 1m 35s\n",
            "48:\tlearn: 0.3651690\ttotal: 30.9s\tremaining: 1m 35s\n",
            "49:\tlearn: 0.3639579\ttotal: 31.5s\tremaining: 1m 34s\n",
            "50:\tlearn: 0.3625757\ttotal: 32.1s\tremaining: 1m 33s\n",
            "51:\tlearn: 0.3612082\ttotal: 32.7s\tremaining: 1m 33s\n",
            "52:\tlearn: 0.3599921\ttotal: 33.3s\tremaining: 1m 32s\n",
            "53:\tlearn: 0.3583504\ttotal: 33.9s\tremaining: 1m 31s\n",
            "54:\tlearn: 0.3567753\ttotal: 34.5s\tremaining: 1m 30s\n",
            "55:\tlearn: 0.3555627\ttotal: 35.1s\tremaining: 1m 30s\n",
            "56:\tlearn: 0.3542684\ttotal: 35.7s\tremaining: 1m 29s\n",
            "57:\tlearn: 0.3531890\ttotal: 36.4s\tremaining: 1m 29s\n",
            "58:\tlearn: 0.3521882\ttotal: 37s\tremaining: 1m 28s\n",
            "59:\tlearn: 0.3511228\ttotal: 37.6s\tremaining: 1m 27s\n",
            "60:\tlearn: 0.3502145\ttotal: 38.2s\tremaining: 1m 27s\n",
            "61:\tlearn: 0.3490474\ttotal: 38.8s\tremaining: 1m 26s\n",
            "62:\tlearn: 0.3480460\ttotal: 39.4s\tremaining: 1m 25s\n",
            "63:\tlearn: 0.3468693\ttotal: 40s\tremaining: 1m 24s\n",
            "64:\tlearn: 0.3454534\ttotal: 40.6s\tremaining: 1m 24s\n",
            "65:\tlearn: 0.3443600\ttotal: 41.2s\tremaining: 1m 23s\n",
            "66:\tlearn: 0.3421292\ttotal: 41.8s\tremaining: 1m 22s\n",
            "67:\tlearn: 0.3409953\ttotal: 42.3s\tremaining: 1m 22s\n",
            "68:\tlearn: 0.3397944\ttotal: 43s\tremaining: 1m 21s\n",
            "69:\tlearn: 0.3389861\ttotal: 43.6s\tremaining: 1m 20s\n",
            "70:\tlearn: 0.3382659\ttotal: 44.2s\tremaining: 1m 20s\n",
            "71:\tlearn: 0.3369905\ttotal: 44.8s\tremaining: 1m 19s\n",
            "72:\tlearn: 0.3350461\ttotal: 45.4s\tremaining: 1m 18s\n",
            "73:\tlearn: 0.3341015\ttotal: 46s\tremaining: 1m 18s\n",
            "74:\tlearn: 0.3331096\ttotal: 46.6s\tremaining: 1m 17s\n",
            "75:\tlearn: 0.3320055\ttotal: 47.2s\tremaining: 1m 16s\n",
            "76:\tlearn: 0.3314389\ttotal: 47.8s\tremaining: 1m 16s\n",
            "77:\tlearn: 0.3306194\ttotal: 48.4s\tremaining: 1m 15s\n",
            "78:\tlearn: 0.3296655\ttotal: 49s\tremaining: 1m 14s\n",
            "79:\tlearn: 0.3289451\ttotal: 49.6s\tremaining: 1m 14s\n",
            "80:\tlearn: 0.3277925\ttotal: 50.2s\tremaining: 1m 13s\n",
            "81:\tlearn: 0.3270819\ttotal: 50.7s\tremaining: 1m 12s\n",
            "82:\tlearn: 0.3263491\ttotal: 51.3s\tremaining: 1m 12s\n",
            "83:\tlearn: 0.3244452\ttotal: 52s\tremaining: 1m 11s\n",
            "84:\tlearn: 0.3236612\ttotal: 52.5s\tremaining: 1m 11s\n",
            "85:\tlearn: 0.3229562\ttotal: 53.1s\tremaining: 1m 10s\n",
            "86:\tlearn: 0.3223913\ttotal: 53.7s\tremaining: 1m 9s\n",
            "87:\tlearn: 0.3215675\ttotal: 54.3s\tremaining: 1m 9s\n",
            "88:\tlearn: 0.3207766\ttotal: 55s\tremaining: 1m 8s\n",
            "89:\tlearn: 0.3199120\ttotal: 55.6s\tremaining: 1m 7s\n",
            "90:\tlearn: 0.3185778\ttotal: 56.2s\tremaining: 1m 7s\n",
            "91:\tlearn: 0.3177866\ttotal: 56.8s\tremaining: 1m 6s\n",
            "92:\tlearn: 0.3172498\ttotal: 57.4s\tremaining: 1m 6s\n",
            "93:\tlearn: 0.3164455\ttotal: 58s\tremaining: 1m 5s\n",
            "94:\tlearn: 0.3157934\ttotal: 58.7s\tremaining: 1m 4s\n",
            "95:\tlearn: 0.3146627\ttotal: 59.3s\tremaining: 1m 4s\n",
            "96:\tlearn: 0.3140768\ttotal: 59.9s\tremaining: 1m 3s\n",
            "97:\tlearn: 0.3133325\ttotal: 1m\tremaining: 1m 2s\n",
            "98:\tlearn: 0.3127319\ttotal: 1m 1s\tremaining: 1m 2s\n",
            "99:\tlearn: 0.3120129\ttotal: 1m 1s\tremaining: 1m 1s\n",
            "100:\tlearn: 0.3112579\ttotal: 1m 2s\tremaining: 1m 1s\n",
            "101:\tlearn: 0.3106465\ttotal: 1m 2s\tremaining: 1m\n",
            "102:\tlearn: 0.3100360\ttotal: 1m 3s\tremaining: 59.8s\n",
            "103:\tlearn: 0.3089112\ttotal: 1m 4s\tremaining: 59.2s\n",
            "104:\tlearn: 0.3084044\ttotal: 1m 4s\tremaining: 58.5s\n",
            "105:\tlearn: 0.3070329\ttotal: 1m 5s\tremaining: 57.9s\n",
            "106:\tlearn: 0.3065244\ttotal: 1m 5s\tremaining: 57.2s\n",
            "107:\tlearn: 0.3058376\ttotal: 1m 6s\tremaining: 56.6s\n",
            "108:\tlearn: 0.3049398\ttotal: 1m 7s\tremaining: 56s\n",
            "109:\tlearn: 0.3038861\ttotal: 1m 7s\tremaining: 55.4s\n",
            "110:\tlearn: 0.3032054\ttotal: 1m 8s\tremaining: 54.7s\n",
            "111:\tlearn: 0.3020658\ttotal: 1m 8s\tremaining: 54.1s\n",
            "112:\tlearn: 0.3014444\ttotal: 1m 9s\tremaining: 53.5s\n",
            "113:\tlearn: 0.3009006\ttotal: 1m 10s\tremaining: 52.9s\n",
            "114:\tlearn: 0.2997425\ttotal: 1m 10s\tremaining: 52.3s\n",
            "115:\tlearn: 0.2991548\ttotal: 1m 11s\tremaining: 51.7s\n",
            "116:\tlearn: 0.2985686\ttotal: 1m 11s\tremaining: 51s\n",
            "117:\tlearn: 0.2980115\ttotal: 1m 12s\tremaining: 50.4s\n",
            "118:\tlearn: 0.2974823\ttotal: 1m 13s\tremaining: 49.7s\n",
            "119:\tlearn: 0.2969116\ttotal: 1m 13s\tremaining: 49.1s\n",
            "120:\tlearn: 0.2962568\ttotal: 1m 14s\tremaining: 48.5s\n",
            "121:\tlearn: 0.2957196\ttotal: 1m 14s\tremaining: 47.8s\n",
            "122:\tlearn: 0.2952704\ttotal: 1m 15s\tremaining: 47.2s\n",
            "123:\tlearn: 0.2947764\ttotal: 1m 16s\tremaining: 46.6s\n",
            "124:\tlearn: 0.2944005\ttotal: 1m 16s\tremaining: 46s\n",
            "125:\tlearn: 0.2939328\ttotal: 1m 17s\tremaining: 45.4s\n",
            "126:\tlearn: 0.2932169\ttotal: 1m 17s\tremaining: 44.7s\n",
            "127:\tlearn: 0.2919578\ttotal: 1m 18s\tremaining: 44.1s\n",
            "128:\tlearn: 0.2913673\ttotal: 1m 19s\tremaining: 43.5s\n",
            "129:\tlearn: 0.2908600\ttotal: 1m 19s\tremaining: 42.9s\n",
            "130:\tlearn: 0.2902782\ttotal: 1m 20s\tremaining: 42.3s\n",
            "131:\tlearn: 0.2898583\ttotal: 1m 20s\tremaining: 41.6s\n",
            "132:\tlearn: 0.2894651\ttotal: 1m 21s\tremaining: 41s\n",
            "133:\tlearn: 0.2889402\ttotal: 1m 22s\tremaining: 40.4s\n",
            "134:\tlearn: 0.2885817\ttotal: 1m 22s\tremaining: 39.8s\n",
            "135:\tlearn: 0.2878873\ttotal: 1m 23s\tremaining: 39.2s\n",
            "136:\tlearn: 0.2875542\ttotal: 1m 23s\tremaining: 38.5s\n",
            "137:\tlearn: 0.2871692\ttotal: 1m 24s\tremaining: 37.9s\n",
            "138:\tlearn: 0.2868147\ttotal: 1m 24s\tremaining: 37.3s\n",
            "139:\tlearn: 0.2862062\ttotal: 1m 25s\tremaining: 36.7s\n",
            "140:\tlearn: 0.2854740\ttotal: 1m 26s\tremaining: 36.1s\n",
            "141:\tlearn: 0.2848582\ttotal: 1m 26s\tremaining: 35.4s\n",
            "142:\tlearn: 0.2843591\ttotal: 1m 27s\tremaining: 34.8s\n",
            "143:\tlearn: 0.2840360\ttotal: 1m 27s\tremaining: 34.2s\n",
            "144:\tlearn: 0.2837171\ttotal: 1m 28s\tremaining: 33.6s\n",
            "145:\tlearn: 0.2831740\ttotal: 1m 29s\tremaining: 32.9s\n",
            "146:\tlearn: 0.2827879\ttotal: 1m 29s\tremaining: 32.3s\n",
            "147:\tlearn: 0.2822461\ttotal: 1m 30s\tremaining: 31.8s\n",
            "148:\tlearn: 0.2816914\ttotal: 1m 30s\tremaining: 31.1s\n",
            "149:\tlearn: 0.2812150\ttotal: 1m 31s\tremaining: 30.5s\n",
            "150:\tlearn: 0.2808451\ttotal: 1m 32s\tremaining: 29.9s\n",
            "151:\tlearn: 0.2804307\ttotal: 1m 32s\tremaining: 29.3s\n",
            "152:\tlearn: 0.2799654\ttotal: 1m 33s\tremaining: 28.7s\n",
            "153:\tlearn: 0.2793070\ttotal: 1m 33s\tremaining: 28.1s\n",
            "154:\tlearn: 0.2789338\ttotal: 1m 34s\tremaining: 27.4s\n",
            "155:\tlearn: 0.2784583\ttotal: 1m 35s\tremaining: 26.8s\n",
            "156:\tlearn: 0.2780900\ttotal: 1m 35s\tremaining: 26.2s\n",
            "157:\tlearn: 0.2777369\ttotal: 1m 36s\tremaining: 25.6s\n",
            "158:\tlearn: 0.2768845\ttotal: 1m 36s\tremaining: 25s\n",
            "159:\tlearn: 0.2765771\ttotal: 1m 37s\tremaining: 24.4s\n",
            "160:\tlearn: 0.2761697\ttotal: 1m 38s\tremaining: 23.8s\n",
            "161:\tlearn: 0.2757981\ttotal: 1m 38s\tremaining: 23.1s\n",
            "162:\tlearn: 0.2753663\ttotal: 1m 39s\tremaining: 22.5s\n",
            "163:\tlearn: 0.2750225\ttotal: 1m 39s\tremaining: 21.9s\n",
            "164:\tlearn: 0.2747113\ttotal: 1m 40s\tremaining: 21.3s\n",
            "165:\tlearn: 0.2740546\ttotal: 1m 41s\tremaining: 20.7s\n",
            "166:\tlearn: 0.2736703\ttotal: 1m 41s\tremaining: 20.1s\n",
            "167:\tlearn: 0.2733304\ttotal: 1m 42s\tremaining: 19.5s\n",
            "168:\tlearn: 0.2728594\ttotal: 1m 42s\tremaining: 18.8s\n",
            "169:\tlearn: 0.2724598\ttotal: 1m 43s\tremaining: 18.2s\n",
            "170:\tlearn: 0.2721679\ttotal: 1m 43s\tremaining: 17.6s\n",
            "171:\tlearn: 0.2719232\ttotal: 1m 44s\tremaining: 17s\n",
            "172:\tlearn: 0.2714111\ttotal: 1m 45s\tremaining: 16.4s\n",
            "173:\tlearn: 0.2710945\ttotal: 1m 45s\tremaining: 15.8s\n",
            "174:\tlearn: 0.2706832\ttotal: 1m 46s\tremaining: 15.2s\n",
            "175:\tlearn: 0.2704049\ttotal: 1m 46s\tremaining: 14.6s\n",
            "176:\tlearn: 0.2700656\ttotal: 1m 47s\tremaining: 14s\n",
            "177:\tlearn: 0.2697946\ttotal: 1m 47s\tremaining: 13.3s\n",
            "178:\tlearn: 0.2695670\ttotal: 1m 48s\tremaining: 12.7s\n",
            "179:\tlearn: 0.2691837\ttotal: 1m 49s\tremaining: 12.1s\n",
            "180:\tlearn: 0.2688249\ttotal: 1m 49s\tremaining: 11.5s\n",
            "181:\tlearn: 0.2684517\ttotal: 1m 50s\tremaining: 10.9s\n",
            "182:\tlearn: 0.2679420\ttotal: 1m 50s\tremaining: 10.3s\n",
            "183:\tlearn: 0.2673425\ttotal: 1m 51s\tremaining: 9.69s\n",
            "184:\tlearn: 0.2670172\ttotal: 1m 52s\tremaining: 9.09s\n",
            "185:\tlearn: 0.2664637\ttotal: 1m 52s\tremaining: 8.48s\n",
            "186:\tlearn: 0.2660340\ttotal: 1m 53s\tremaining: 7.88s\n",
            "187:\tlearn: 0.2655528\ttotal: 1m 53s\tremaining: 7.27s\n",
            "188:\tlearn: 0.2651288\ttotal: 1m 54s\tremaining: 6.66s\n",
            "189:\tlearn: 0.2647540\ttotal: 1m 55s\tremaining: 6.05s\n",
            "190:\tlearn: 0.2643758\ttotal: 1m 55s\tremaining: 5.45s\n",
            "191:\tlearn: 0.2640266\ttotal: 1m 56s\tremaining: 4.84s\n",
            "192:\tlearn: 0.2637387\ttotal: 1m 56s\tremaining: 4.24s\n",
            "193:\tlearn: 0.2634248\ttotal: 1m 57s\tremaining: 3.63s\n",
            "194:\tlearn: 0.2630336\ttotal: 1m 57s\tremaining: 3.02s\n",
            "195:\tlearn: 0.2628322\ttotal: 1m 58s\tremaining: 2.42s\n",
            "196:\tlearn: 0.2624940\ttotal: 1m 59s\tremaining: 1.81s\n",
            "197:\tlearn: 0.2622819\ttotal: 1m 59s\tremaining: 1.21s\n",
            "198:\tlearn: 0.2618699\ttotal: 2m\tremaining: 604ms\n",
            "199:\tlearn: 0.2614032\ttotal: 2m\tremaining: 0us\n",
            "[CV 4/5; 1/1] END ...................depth=3, iterations=200; total time= 2.2min\n",
            "[CV 5/5; 1/1] START depth=3, iterations=200.....................................\n",
            "Learning rate set to 0.324687\n",
            "0:\tlearn: 0.6197845\ttotal: 741ms\tremaining: 2m 27s\n",
            "1:\tlearn: 0.5804597\ttotal: 1.37s\tremaining: 2m 15s\n",
            "2:\tlearn: 0.5536346\ttotal: 2.02s\tremaining: 2m 12s\n",
            "3:\tlearn: 0.5381588\ttotal: 2.67s\tremaining: 2m 10s\n",
            "4:\tlearn: 0.5265090\ttotal: 3.31s\tremaining: 2m 9s\n",
            "5:\tlearn: 0.5169985\ttotal: 3.93s\tremaining: 2m 7s\n",
            "6:\tlearn: 0.5037984\ttotal: 4.58s\tremaining: 2m 6s\n",
            "7:\tlearn: 0.4964766\ttotal: 5.22s\tremaining: 2m 5s\n",
            "8:\tlearn: 0.4866740\ttotal: 5.83s\tremaining: 2m 3s\n",
            "9:\tlearn: 0.4792591\ttotal: 6.46s\tremaining: 2m 2s\n",
            "10:\tlearn: 0.4735887\ttotal: 7.08s\tremaining: 2m 1s\n",
            "11:\tlearn: 0.4641821\ttotal: 7.7s\tremaining: 2m\n",
            "12:\tlearn: 0.4595902\ttotal: 8.35s\tremaining: 2m\n",
            "13:\tlearn: 0.4555066\ttotal: 8.99s\tremaining: 1m 59s\n",
            "14:\tlearn: 0.4508699\ttotal: 9.6s\tremaining: 1m 58s\n",
            "15:\tlearn: 0.4441628\ttotal: 10.2s\tremaining: 1m 57s\n",
            "16:\tlearn: 0.4398231\ttotal: 10.8s\tremaining: 1m 56s\n",
            "17:\tlearn: 0.4366897\ttotal: 11.4s\tremaining: 1m 55s\n",
            "18:\tlearn: 0.4338878\ttotal: 12.1s\tremaining: 1m 54s\n",
            "19:\tlearn: 0.4283777\ttotal: 12.7s\tremaining: 1m 54s\n",
            "20:\tlearn: 0.4250983\ttotal: 13.3s\tremaining: 1m 53s\n",
            "21:\tlearn: 0.4205660\ttotal: 13.9s\tremaining: 1m 52s\n",
            "22:\tlearn: 0.4178199\ttotal: 14.5s\tremaining: 1m 51s\n",
            "23:\tlearn: 0.4151788\ttotal: 15.1s\tremaining: 1m 50s\n",
            "24:\tlearn: 0.4129968\ttotal: 15.7s\tremaining: 1m 50s\n",
            "25:\tlearn: 0.4107141\ttotal: 16.3s\tremaining: 1m 49s\n",
            "26:\tlearn: 0.4078957\ttotal: 17s\tremaining: 1m 48s\n",
            "27:\tlearn: 0.4051312\ttotal: 17.6s\tremaining: 1m 47s\n",
            "28:\tlearn: 0.4032032\ttotal: 18.3s\tremaining: 1m 47s\n",
            "29:\tlearn: 0.4009196\ttotal: 18.9s\tremaining: 1m 47s\n",
            "30:\tlearn: 0.3990577\ttotal: 19.5s\tremaining: 1m 46s\n",
            "31:\tlearn: 0.3974581\ttotal: 20.2s\tremaining: 1m 45s\n",
            "32:\tlearn: 0.3956000\ttotal: 20.8s\tremaining: 1m 45s\n",
            "33:\tlearn: 0.3934531\ttotal: 21.4s\tremaining: 1m 44s\n",
            "34:\tlearn: 0.3921565\ttotal: 22s\tremaining: 1m 43s\n",
            "35:\tlearn: 0.3890385\ttotal: 22.6s\tremaining: 1m 43s\n",
            "36:\tlearn: 0.3868932\ttotal: 23.2s\tremaining: 1m 42s\n",
            "37:\tlearn: 0.3846996\ttotal: 23.8s\tremaining: 1m 41s\n",
            "38:\tlearn: 0.3830020\ttotal: 24.5s\tremaining: 1m 41s\n",
            "39:\tlearn: 0.3812931\ttotal: 25.1s\tremaining: 1m 40s\n",
            "40:\tlearn: 0.3773713\ttotal: 25.7s\tremaining: 1m 39s\n",
            "41:\tlearn: 0.3751679\ttotal: 26.3s\tremaining: 1m 39s\n",
            "42:\tlearn: 0.3731500\ttotal: 27s\tremaining: 1m 38s\n",
            "43:\tlearn: 0.3712301\ttotal: 27.6s\tremaining: 1m 37s\n",
            "44:\tlearn: 0.3697040\ttotal: 28.2s\tremaining: 1m 37s\n",
            "45:\tlearn: 0.3683395\ttotal: 28.8s\tremaining: 1m 36s\n",
            "46:\tlearn: 0.3663935\ttotal: 29.4s\tremaining: 1m 35s\n",
            "47:\tlearn: 0.3648088\ttotal: 30s\tremaining: 1m 34s\n",
            "48:\tlearn: 0.3630918\ttotal: 30.6s\tremaining: 1m 34s\n",
            "49:\tlearn: 0.3620005\ttotal: 31.2s\tremaining: 1m 33s\n",
            "50:\tlearn: 0.3597148\ttotal: 31.7s\tremaining: 1m 32s\n",
            "51:\tlearn: 0.3582792\ttotal: 32.3s\tremaining: 1m 32s\n",
            "52:\tlearn: 0.3568236\ttotal: 32.9s\tremaining: 1m 31s\n",
            "53:\tlearn: 0.3555818\ttotal: 33.5s\tremaining: 1m 30s\n",
            "54:\tlearn: 0.3544101\ttotal: 34.1s\tremaining: 1m 30s\n",
            "55:\tlearn: 0.3532505\ttotal: 34.8s\tremaining: 1m 29s\n",
            "56:\tlearn: 0.3518375\ttotal: 35.3s\tremaining: 1m 28s\n",
            "57:\tlearn: 0.3504250\ttotal: 35.9s\tremaining: 1m 27s\n",
            "58:\tlearn: 0.3491941\ttotal: 36.6s\tremaining: 1m 27s\n",
            "59:\tlearn: 0.3458792\ttotal: 37.2s\tremaining: 1m 26s\n",
            "60:\tlearn: 0.3447524\ttotal: 37.7s\tremaining: 1m 26s\n",
            "61:\tlearn: 0.3431738\ttotal: 38.3s\tremaining: 1m 25s\n",
            "62:\tlearn: 0.3421202\ttotal: 39s\tremaining: 1m 24s\n",
            "63:\tlearn: 0.3410003\ttotal: 39.6s\tremaining: 1m 24s\n",
            "64:\tlearn: 0.3399061\ttotal: 40.2s\tremaining: 1m 23s\n",
            "65:\tlearn: 0.3388176\ttotal: 40.8s\tremaining: 1m 22s\n",
            "66:\tlearn: 0.3378923\ttotal: 41.4s\tremaining: 1m 22s\n",
            "67:\tlearn: 0.3368027\ttotal: 42.1s\tremaining: 1m 21s\n",
            "68:\tlearn: 0.3357222\ttotal: 42.7s\tremaining: 1m 21s\n",
            "69:\tlearn: 0.3341670\ttotal: 43.3s\tremaining: 1m 20s\n",
            "70:\tlearn: 0.3332223\ttotal: 43.9s\tremaining: 1m 19s\n",
            "71:\tlearn: 0.3324345\ttotal: 44.5s\tremaining: 1m 19s\n",
            "72:\tlearn: 0.3315546\ttotal: 45.2s\tremaining: 1m 18s\n",
            "73:\tlearn: 0.3305966\ttotal: 45.8s\tremaining: 1m 17s\n",
            "74:\tlearn: 0.3296383\ttotal: 46.4s\tremaining: 1m 17s\n",
            "75:\tlearn: 0.3280810\ttotal: 47s\tremaining: 1m 16s\n",
            "76:\tlearn: 0.3270591\ttotal: 47.7s\tremaining: 1m 16s\n",
            "77:\tlearn: 0.3245340\ttotal: 48.3s\tremaining: 1m 15s\n",
            "78:\tlearn: 0.3237287\ttotal: 48.9s\tremaining: 1m 14s\n",
            "79:\tlearn: 0.3228133\ttotal: 49.5s\tremaining: 1m 14s\n",
            "80:\tlearn: 0.3220157\ttotal: 50.1s\tremaining: 1m 13s\n",
            "81:\tlearn: 0.3213556\ttotal: 50.6s\tremaining: 1m 12s\n",
            "82:\tlearn: 0.3205653\ttotal: 51.3s\tremaining: 1m 12s\n",
            "83:\tlearn: 0.3196627\ttotal: 51.8s\tremaining: 1m 11s\n",
            "84:\tlearn: 0.3188540\ttotal: 52.4s\tremaining: 1m 10s\n",
            "85:\tlearn: 0.3181005\ttotal: 53.1s\tremaining: 1m 10s\n",
            "86:\tlearn: 0.3173219\ttotal: 53.7s\tremaining: 1m 9s\n",
            "87:\tlearn: 0.3162095\ttotal: 54.3s\tremaining: 1m 9s\n",
            "88:\tlearn: 0.3154156\ttotal: 54.9s\tremaining: 1m 8s\n",
            "89:\tlearn: 0.3141088\ttotal: 55.4s\tremaining: 1m 7s\n",
            "90:\tlearn: 0.3135332\ttotal: 56s\tremaining: 1m 7s\n",
            "91:\tlearn: 0.3129185\ttotal: 56.6s\tremaining: 1m 6s\n",
            "92:\tlearn: 0.3121054\ttotal: 57.2s\tremaining: 1m 5s\n",
            "93:\tlearn: 0.3115161\ttotal: 57.8s\tremaining: 1m 5s\n",
            "94:\tlearn: 0.3107954\ttotal: 58.4s\tremaining: 1m 4s\n",
            "95:\tlearn: 0.3102132\ttotal: 58.9s\tremaining: 1m 3s\n",
            "96:\tlearn: 0.3095082\ttotal: 59.5s\tremaining: 1m 3s\n",
            "97:\tlearn: 0.3086406\ttotal: 1m\tremaining: 1m 2s\n",
            "98:\tlearn: 0.3075354\ttotal: 1m\tremaining: 1m 1s\n",
            "99:\tlearn: 0.3068876\ttotal: 1m 1s\tremaining: 1m 1s\n",
            "100:\tlearn: 0.3050395\ttotal: 1m 1s\tremaining: 1m\n",
            "101:\tlearn: 0.3041173\ttotal: 1m 2s\tremaining: 1m\n",
            "102:\tlearn: 0.3034954\ttotal: 1m 3s\tremaining: 59.4s\n",
            "103:\tlearn: 0.3028577\ttotal: 1m 3s\tremaining: 58.7s\n",
            "104:\tlearn: 0.3023123\ttotal: 1m 4s\tremaining: 58.1s\n",
            "105:\tlearn: 0.3012044\ttotal: 1m 4s\tremaining: 57.5s\n",
            "106:\tlearn: 0.3004008\ttotal: 1m 5s\tremaining: 56.9s\n",
            "107:\tlearn: 0.2997571\ttotal: 1m 6s\tremaining: 56.3s\n",
            "108:\tlearn: 0.2991906\ttotal: 1m 6s\tremaining: 55.6s\n",
            "109:\tlearn: 0.2985254\ttotal: 1m 7s\tremaining: 55s\n",
            "110:\tlearn: 0.2978101\ttotal: 1m 7s\tremaining: 54.4s\n",
            "111:\tlearn: 0.2970607\ttotal: 1m 8s\tremaining: 53.8s\n",
            "112:\tlearn: 0.2966926\ttotal: 1m 8s\tremaining: 53.1s\n",
            "113:\tlearn: 0.2961867\ttotal: 1m 9s\tremaining: 52.5s\n",
            "114:\tlearn: 0.2957234\ttotal: 1m 10s\tremaining: 51.9s\n",
            "115:\tlearn: 0.2951564\ttotal: 1m 10s\tremaining: 51.2s\n",
            "116:\tlearn: 0.2943487\ttotal: 1m 11s\tremaining: 50.6s\n",
            "117:\tlearn: 0.2937136\ttotal: 1m 11s\tremaining: 50s\n",
            "118:\tlearn: 0.2930403\ttotal: 1m 12s\tremaining: 49.3s\n",
            "119:\tlearn: 0.2923480\ttotal: 1m 13s\tremaining: 48.7s\n",
            "120:\tlearn: 0.2919521\ttotal: 1m 13s\tremaining: 48.1s\n",
            "121:\tlearn: 0.2914652\ttotal: 1m 14s\tremaining: 47.5s\n",
            "122:\tlearn: 0.2910095\ttotal: 1m 14s\tremaining: 46.8s\n",
            "123:\tlearn: 0.2904686\ttotal: 1m 15s\tremaining: 46.2s\n",
            "124:\tlearn: 0.2900442\ttotal: 1m 16s\tremaining: 45.6s\n",
            "125:\tlearn: 0.2895490\ttotal: 1m 16s\tremaining: 45s\n",
            "126:\tlearn: 0.2889469\ttotal: 1m 17s\tremaining: 44.3s\n",
            "127:\tlearn: 0.2885583\ttotal: 1m 17s\tremaining: 43.7s\n",
            "128:\tlearn: 0.2881214\ttotal: 1m 18s\tremaining: 43.1s\n",
            "129:\tlearn: 0.2876177\ttotal: 1m 18s\tremaining: 42.5s\n",
            "130:\tlearn: 0.2871529\ttotal: 1m 19s\tremaining: 41.9s\n",
            "131:\tlearn: 0.2866812\ttotal: 1m 20s\tremaining: 41.3s\n",
            "132:\tlearn: 0.2861030\ttotal: 1m 20s\tremaining: 40.7s\n",
            "133:\tlearn: 0.2857082\ttotal: 1m 21s\tremaining: 40s\n",
            "134:\tlearn: 0.2852492\ttotal: 1m 21s\tremaining: 39.4s\n",
            "135:\tlearn: 0.2846727\ttotal: 1m 22s\tremaining: 38.8s\n",
            "136:\tlearn: 0.2840940\ttotal: 1m 23s\tremaining: 38.2s\n",
            "137:\tlearn: 0.2837056\ttotal: 1m 23s\tremaining: 37.6s\n",
            "138:\tlearn: 0.2832369\ttotal: 1m 24s\tremaining: 36.9s\n",
            "139:\tlearn: 0.2827985\ttotal: 1m 24s\tremaining: 36.3s\n",
            "140:\tlearn: 0.2822670\ttotal: 1m 25s\tremaining: 35.7s\n",
            "141:\tlearn: 0.2816885\ttotal: 1m 25s\tremaining: 35.1s\n",
            "142:\tlearn: 0.2813994\ttotal: 1m 26s\tremaining: 34.5s\n",
            "143:\tlearn: 0.2808440\ttotal: 1m 27s\tremaining: 33.9s\n",
            "144:\tlearn: 0.2803929\ttotal: 1m 27s\tremaining: 33.3s\n",
            "145:\tlearn: 0.2799253\ttotal: 1m 28s\tremaining: 32.7s\n",
            "146:\tlearn: 0.2794488\ttotal: 1m 28s\tremaining: 32.1s\n",
            "147:\tlearn: 0.2788861\ttotal: 1m 29s\tremaining: 31.5s\n",
            "148:\tlearn: 0.2785658\ttotal: 1m 30s\tremaining: 30.9s\n",
            "149:\tlearn: 0.2781820\ttotal: 1m 30s\tremaining: 30.2s\n",
            "150:\tlearn: 0.2778190\ttotal: 1m 31s\tremaining: 29.6s\n",
            "151:\tlearn: 0.2773919\ttotal: 1m 31s\tremaining: 29s\n",
            "152:\tlearn: 0.2771099\ttotal: 1m 32s\tremaining: 28.4s\n",
            "153:\tlearn: 0.2767177\ttotal: 1m 33s\tremaining: 27.8s\n",
            "154:\tlearn: 0.2762653\ttotal: 1m 33s\tremaining: 27.2s\n",
            "155:\tlearn: 0.2759540\ttotal: 1m 34s\tremaining: 26.6s\n",
            "156:\tlearn: 0.2756384\ttotal: 1m 34s\tremaining: 26s\n",
            "157:\tlearn: 0.2752786\ttotal: 1m 35s\tremaining: 25.3s\n",
            "158:\tlearn: 0.2748174\ttotal: 1m 35s\tremaining: 24.7s\n",
            "159:\tlearn: 0.2742639\ttotal: 1m 36s\tremaining: 24.1s\n",
            "160:\tlearn: 0.2738480\ttotal: 1m 37s\tremaining: 23.5s\n",
            "161:\tlearn: 0.2735046\ttotal: 1m 37s\tremaining: 22.9s\n",
            "162:\tlearn: 0.2731691\ttotal: 1m 38s\tremaining: 22.3s\n",
            "163:\tlearn: 0.2728854\ttotal: 1m 38s\tremaining: 21.7s\n",
            "164:\tlearn: 0.2725485\ttotal: 1m 39s\tremaining: 21.1s\n",
            "165:\tlearn: 0.2721636\ttotal: 1m 40s\tremaining: 20.5s\n",
            "166:\tlearn: 0.2717842\ttotal: 1m 40s\tremaining: 19.9s\n",
            "167:\tlearn: 0.2714057\ttotal: 1m 41s\tremaining: 19.3s\n",
            "168:\tlearn: 0.2710093\ttotal: 1m 41s\tremaining: 18.7s\n",
            "169:\tlearn: 0.2706926\ttotal: 1m 42s\tremaining: 18.1s\n",
            "170:\tlearn: 0.2701863\ttotal: 1m 43s\tremaining: 17.5s\n",
            "171:\tlearn: 0.2698481\ttotal: 1m 43s\tremaining: 16.9s\n",
            "172:\tlearn: 0.2695667\ttotal: 1m 44s\tremaining: 16.3s\n",
            "173:\tlearn: 0.2690663\ttotal: 1m 44s\tremaining: 15.7s\n",
            "174:\tlearn: 0.2686776\ttotal: 1m 45s\tremaining: 15.1s\n",
            "175:\tlearn: 0.2683780\ttotal: 1m 46s\tremaining: 14.5s\n",
            "176:\tlearn: 0.2679297\ttotal: 1m 46s\tremaining: 13.9s\n",
            "177:\tlearn: 0.2676582\ttotal: 1m 47s\tremaining: 13.2s\n",
            "178:\tlearn: 0.2673402\ttotal: 1m 47s\tremaining: 12.6s\n",
            "179:\tlearn: 0.2667608\ttotal: 1m 48s\tremaining: 12.1s\n",
            "180:\tlearn: 0.2663847\ttotal: 1m 49s\tremaining: 11.4s\n",
            "181:\tlearn: 0.2661167\ttotal: 1m 49s\tremaining: 10.8s\n",
            "182:\tlearn: 0.2657302\ttotal: 1m 50s\tremaining: 10.2s\n",
            "183:\tlearn: 0.2652972\ttotal: 1m 50s\tremaining: 9.64s\n",
            "184:\tlearn: 0.2650695\ttotal: 1m 51s\tremaining: 9.04s\n",
            "185:\tlearn: 0.2647989\ttotal: 1m 52s\tremaining: 8.43s\n",
            "186:\tlearn: 0.2644163\ttotal: 1m 52s\tremaining: 7.83s\n",
            "187:\tlearn: 0.2637672\ttotal: 1m 53s\tremaining: 7.23s\n",
            "188:\tlearn: 0.2630458\ttotal: 1m 53s\tremaining: 6.63s\n",
            "189:\tlearn: 0.2627747\ttotal: 1m 54s\tremaining: 6.02s\n",
            "190:\tlearn: 0.2621952\ttotal: 1m 55s\tremaining: 5.42s\n",
            "191:\tlearn: 0.2618015\ttotal: 1m 55s\tremaining: 4.82s\n",
            "192:\tlearn: 0.2614621\ttotal: 1m 56s\tremaining: 4.22s\n",
            "193:\tlearn: 0.2610000\ttotal: 1m 56s\tremaining: 3.61s\n",
            "194:\tlearn: 0.2606928\ttotal: 1m 57s\tremaining: 3.01s\n",
            "195:\tlearn: 0.2604048\ttotal: 1m 57s\tremaining: 2.41s\n",
            "196:\tlearn: 0.2600601\ttotal: 1m 58s\tremaining: 1.8s\n",
            "197:\tlearn: 0.2597683\ttotal: 1m 59s\tremaining: 1.2s\n",
            "198:\tlearn: 0.2594834\ttotal: 1m 59s\tremaining: 602ms\n",
            "199:\tlearn: 0.2592556\ttotal: 2m\tremaining: 0us\n",
            "[CV 5/5; 1/1] END ...................depth=3, iterations=200; total time= 2.2min\n",
            "Learning rate set to 0.357145\n",
            "0:\tlearn: 0.6086570\ttotal: 955ms\tremaining: 3m 10s\n",
            "1:\tlearn: 0.5722209\ttotal: 1.75s\tremaining: 2m 53s\n",
            "2:\tlearn: 0.5478055\ttotal: 2.55s\tremaining: 2m 47s\n",
            "3:\tlearn: 0.5295776\ttotal: 3.34s\tremaining: 2m 43s\n",
            "4:\tlearn: 0.5193231\ttotal: 4.16s\tremaining: 2m 42s\n",
            "5:\tlearn: 0.5053100\ttotal: 4.96s\tremaining: 2m 40s\n",
            "6:\tlearn: 0.4927582\ttotal: 5.75s\tremaining: 2m 38s\n",
            "7:\tlearn: 0.4842167\ttotal: 6.52s\tremaining: 2m 36s\n",
            "8:\tlearn: 0.4781485\ttotal: 7.29s\tremaining: 2m 34s\n",
            "9:\tlearn: 0.4718025\ttotal: 8.07s\tremaining: 2m 33s\n",
            "10:\tlearn: 0.4656659\ttotal: 8.85s\tremaining: 2m 32s\n",
            "11:\tlearn: 0.4592303\ttotal: 9.62s\tremaining: 2m 30s\n",
            "12:\tlearn: 0.4494323\ttotal: 10.4s\tremaining: 2m 29s\n",
            "13:\tlearn: 0.4443077\ttotal: 11.2s\tremaining: 2m 28s\n",
            "14:\tlearn: 0.4404448\ttotal: 11.9s\tremaining: 2m 27s\n",
            "15:\tlearn: 0.4359365\ttotal: 12.7s\tremaining: 2m 26s\n",
            "16:\tlearn: 0.4326755\ttotal: 13.5s\tremaining: 2m 25s\n",
            "17:\tlearn: 0.4283903\ttotal: 14.4s\tremaining: 2m 25s\n",
            "18:\tlearn: 0.4245918\ttotal: 15.1s\tremaining: 2m 24s\n",
            "19:\tlearn: 0.4204249\ttotal: 15.9s\tremaining: 2m 23s\n",
            "20:\tlearn: 0.4175122\ttotal: 16.7s\tremaining: 2m 22s\n",
            "21:\tlearn: 0.4153796\ttotal: 17.5s\tremaining: 2m 21s\n",
            "22:\tlearn: 0.4116323\ttotal: 18.3s\tremaining: 2m 20s\n",
            "23:\tlearn: 0.4085569\ttotal: 19.1s\tremaining: 2m 19s\n",
            "24:\tlearn: 0.4056344\ttotal: 19.9s\tremaining: 2m 19s\n",
            "25:\tlearn: 0.4038000\ttotal: 20.6s\tremaining: 2m 18s\n",
            "26:\tlearn: 0.4017625\ttotal: 21.4s\tremaining: 2m 16s\n",
            "27:\tlearn: 0.3999988\ttotal: 22.1s\tremaining: 2m 15s\n",
            "28:\tlearn: 0.3982089\ttotal: 22.9s\tremaining: 2m 15s\n",
            "29:\tlearn: 0.3965728\ttotal: 23.7s\tremaining: 2m 14s\n",
            "30:\tlearn: 0.3930127\ttotal: 24.5s\tremaining: 2m 13s\n",
            "31:\tlearn: 0.3899787\ttotal: 25.2s\tremaining: 2m 12s\n",
            "32:\tlearn: 0.3862770\ttotal: 26s\tremaining: 2m 11s\n",
            "33:\tlearn: 0.3844593\ttotal: 26.8s\tremaining: 2m 10s\n",
            "34:\tlearn: 0.3826745\ttotal: 27.6s\tremaining: 2m 10s\n",
            "35:\tlearn: 0.3810521\ttotal: 28.4s\tremaining: 2m 9s\n",
            "36:\tlearn: 0.3790486\ttotal: 29.1s\tremaining: 2m 8s\n",
            "37:\tlearn: 0.3773435\ttotal: 29.9s\tremaining: 2m 7s\n",
            "38:\tlearn: 0.3758077\ttotal: 30.7s\tremaining: 2m 6s\n",
            "39:\tlearn: 0.3726640\ttotal: 31.5s\tremaining: 2m 5s\n",
            "40:\tlearn: 0.3713037\ttotal: 32.2s\tremaining: 2m 4s\n",
            "41:\tlearn: 0.3692075\ttotal: 33s\tremaining: 2m 4s\n",
            "42:\tlearn: 0.3670315\ttotal: 33.7s\tremaining: 2m 3s\n",
            "43:\tlearn: 0.3656171\ttotal: 34.5s\tremaining: 2m 2s\n",
            "44:\tlearn: 0.3634071\ttotal: 35.2s\tremaining: 2m 1s\n",
            "45:\tlearn: 0.3611540\ttotal: 36s\tremaining: 2m\n",
            "46:\tlearn: 0.3598764\ttotal: 36.7s\tremaining: 1m 59s\n",
            "47:\tlearn: 0.3587656\ttotal: 37.6s\tremaining: 1m 58s\n",
            "48:\tlearn: 0.3574093\ttotal: 38.4s\tremaining: 1m 58s\n",
            "49:\tlearn: 0.3559171\ttotal: 39.1s\tremaining: 1m 57s\n",
            "50:\tlearn: 0.3541291\ttotal: 39.9s\tremaining: 1m 56s\n",
            "51:\tlearn: 0.3512218\ttotal: 40.6s\tremaining: 1m 55s\n",
            "52:\tlearn: 0.3497428\ttotal: 41.4s\tremaining: 1m 54s\n",
            "53:\tlearn: 0.3480501\ttotal: 42.2s\tremaining: 1m 54s\n",
            "54:\tlearn: 0.3468186\ttotal: 42.9s\tremaining: 1m 53s\n",
            "55:\tlearn: 0.3456222\ttotal: 43.6s\tremaining: 1m 52s\n",
            "56:\tlearn: 0.3441751\ttotal: 44.4s\tremaining: 1m 51s\n",
            "57:\tlearn: 0.3429165\ttotal: 45.2s\tremaining: 1m 50s\n",
            "58:\tlearn: 0.3410184\ttotal: 45.9s\tremaining: 1m 49s\n",
            "59:\tlearn: 0.3401076\ttotal: 46.6s\tremaining: 1m 48s\n",
            "60:\tlearn: 0.3388866\ttotal: 47.4s\tremaining: 1m 47s\n",
            "61:\tlearn: 0.3376919\ttotal: 48.2s\tremaining: 1m 47s\n",
            "62:\tlearn: 0.3364523\ttotal: 48.9s\tremaining: 1m 46s\n",
            "63:\tlearn: 0.3352897\ttotal: 49.7s\tremaining: 1m 45s\n",
            "64:\tlearn: 0.3343423\ttotal: 50.5s\tremaining: 1m 44s\n",
            "65:\tlearn: 0.3335514\ttotal: 51.2s\tremaining: 1m 43s\n",
            "66:\tlearn: 0.3325886\ttotal: 52s\tremaining: 1m 43s\n",
            "67:\tlearn: 0.3312874\ttotal: 52.7s\tremaining: 1m 42s\n",
            "68:\tlearn: 0.3303595\ttotal: 53.5s\tremaining: 1m 41s\n",
            "69:\tlearn: 0.3296049\ttotal: 54.2s\tremaining: 1m 40s\n",
            "70:\tlearn: 0.3286094\ttotal: 55s\tremaining: 1m 39s\n",
            "71:\tlearn: 0.3278118\ttotal: 55.7s\tremaining: 1m 39s\n",
            "72:\tlearn: 0.3264978\ttotal: 56.5s\tremaining: 1m 38s\n",
            "73:\tlearn: 0.3254314\ttotal: 57.2s\tremaining: 1m 37s\n",
            "74:\tlearn: 0.3246320\ttotal: 58s\tremaining: 1m 36s\n",
            "75:\tlearn: 0.3238214\ttotal: 58.7s\tremaining: 1m 35s\n",
            "76:\tlearn: 0.3230774\ttotal: 59.4s\tremaining: 1m 34s\n",
            "77:\tlearn: 0.3221873\ttotal: 1m\tremaining: 1m 34s\n",
            "78:\tlearn: 0.3213368\ttotal: 1m\tremaining: 1m 33s\n",
            "79:\tlearn: 0.3204203\ttotal: 1m 1s\tremaining: 1m 32s\n",
            "80:\tlearn: 0.3196127\ttotal: 1m 2s\tremaining: 1m 31s\n",
            "81:\tlearn: 0.3187909\ttotal: 1m 3s\tremaining: 1m 30s\n",
            "82:\tlearn: 0.3179015\ttotal: 1m 3s\tremaining: 1m 30s\n",
            "83:\tlearn: 0.3171277\ttotal: 1m 4s\tremaining: 1m 29s\n",
            "84:\tlearn: 0.3161638\ttotal: 1m 5s\tremaining: 1m 28s\n",
            "85:\tlearn: 0.3154159\ttotal: 1m 6s\tremaining: 1m 27s\n",
            "86:\tlearn: 0.3146081\ttotal: 1m 6s\tremaining: 1m 26s\n",
            "87:\tlearn: 0.3137827\ttotal: 1m 7s\tremaining: 1m 26s\n",
            "88:\tlearn: 0.3129561\ttotal: 1m 8s\tremaining: 1m 25s\n",
            "89:\tlearn: 0.3123692\ttotal: 1m 9s\tremaining: 1m 24s\n",
            "90:\tlearn: 0.3117698\ttotal: 1m 9s\tremaining: 1m 23s\n",
            "91:\tlearn: 0.3108939\ttotal: 1m 10s\tremaining: 1m 22s\n",
            "92:\tlearn: 0.3103525\ttotal: 1m 11s\tremaining: 1m 22s\n",
            "93:\tlearn: 0.3098213\ttotal: 1m 12s\tremaining: 1m 21s\n",
            "94:\tlearn: 0.3081965\ttotal: 1m 12s\tremaining: 1m 20s\n",
            "95:\tlearn: 0.3076780\ttotal: 1m 13s\tremaining: 1m 19s\n",
            "96:\tlearn: 0.3069509\ttotal: 1m 14s\tremaining: 1m 18s\n",
            "97:\tlearn: 0.3057119\ttotal: 1m 14s\tremaining: 1m 18s\n",
            "98:\tlearn: 0.3051650\ttotal: 1m 15s\tremaining: 1m 17s\n",
            "99:\tlearn: 0.3045260\ttotal: 1m 16s\tremaining: 1m 16s\n",
            "100:\tlearn: 0.3038844\ttotal: 1m 17s\tremaining: 1m 15s\n",
            "101:\tlearn: 0.3033540\ttotal: 1m 17s\tremaining: 1m 14s\n",
            "102:\tlearn: 0.3027169\ttotal: 1m 18s\tremaining: 1m 14s\n",
            "103:\tlearn: 0.3022149\ttotal: 1m 19s\tremaining: 1m 13s\n",
            "104:\tlearn: 0.2996580\ttotal: 1m 20s\tremaining: 1m 12s\n",
            "105:\tlearn: 0.2989598\ttotal: 1m 20s\tremaining: 1m 11s\n",
            "106:\tlearn: 0.2984699\ttotal: 1m 21s\tremaining: 1m 10s\n",
            "107:\tlearn: 0.2978471\ttotal: 1m 22s\tremaining: 1m 10s\n",
            "108:\tlearn: 0.2971707\ttotal: 1m 23s\tremaining: 1m 9s\n",
            "109:\tlearn: 0.2965479\ttotal: 1m 23s\tremaining: 1m 8s\n",
            "110:\tlearn: 0.2958843\ttotal: 1m 24s\tremaining: 1m 7s\n",
            "111:\tlearn: 0.2953553\ttotal: 1m 25s\tremaining: 1m 7s\n",
            "112:\tlearn: 0.2946288\ttotal: 1m 26s\tremaining: 1m 6s\n",
            "113:\tlearn: 0.2941336\ttotal: 1m 26s\tremaining: 1m 5s\n",
            "114:\tlearn: 0.2935109\ttotal: 1m 27s\tremaining: 1m 4s\n",
            "115:\tlearn: 0.2925658\ttotal: 1m 28s\tremaining: 1m 3s\n",
            "116:\tlearn: 0.2922135\ttotal: 1m 29s\tremaining: 1m 3s\n",
            "117:\tlearn: 0.2914072\ttotal: 1m 29s\tremaining: 1m 2s\n",
            "118:\tlearn: 0.2909238\ttotal: 1m 30s\tremaining: 1m 1s\n",
            "119:\tlearn: 0.2903179\ttotal: 1m 31s\tremaining: 1m\n",
            "120:\tlearn: 0.2898609\ttotal: 1m 32s\tremaining: 1m\n",
            "121:\tlearn: 0.2892751\ttotal: 1m 32s\tremaining: 59.4s\n",
            "122:\tlearn: 0.2887058\ttotal: 1m 33s\tremaining: 58.6s\n",
            "123:\tlearn: 0.2882039\ttotal: 1m 34s\tremaining: 57.9s\n",
            "124:\tlearn: 0.2875772\ttotal: 1m 35s\tremaining: 57.1s\n",
            "125:\tlearn: 0.2871330\ttotal: 1m 35s\tremaining: 56.3s\n",
            "126:\tlearn: 0.2866203\ttotal: 1m 36s\tremaining: 55.5s\n",
            "127:\tlearn: 0.2861422\ttotal: 1m 37s\tremaining: 54.7s\n",
            "128:\tlearn: 0.2857135\ttotal: 1m 38s\tremaining: 54s\n",
            "129:\tlearn: 0.2852115\ttotal: 1m 38s\tremaining: 53.2s\n",
            "130:\tlearn: 0.2845170\ttotal: 1m 39s\tremaining: 52.4s\n",
            "131:\tlearn: 0.2839756\ttotal: 1m 40s\tremaining: 51.7s\n",
            "132:\tlearn: 0.2832730\ttotal: 1m 41s\tremaining: 50.9s\n",
            "133:\tlearn: 0.2825617\ttotal: 1m 41s\tremaining: 50.2s\n",
            "134:\tlearn: 0.2820725\ttotal: 1m 42s\tremaining: 49.4s\n",
            "135:\tlearn: 0.2817857\ttotal: 1m 43s\tremaining: 48.6s\n",
            "136:\tlearn: 0.2813944\ttotal: 1m 44s\tremaining: 47.9s\n",
            "137:\tlearn: 0.2808307\ttotal: 1m 44s\tremaining: 47.1s\n",
            "138:\tlearn: 0.2803387\ttotal: 1m 45s\tremaining: 46.4s\n",
            "139:\tlearn: 0.2800186\ttotal: 1m 46s\tremaining: 45.6s\n",
            "140:\tlearn: 0.2796422\ttotal: 1m 47s\tremaining: 44.8s\n",
            "141:\tlearn: 0.2792929\ttotal: 1m 47s\tremaining: 44s\n",
            "142:\tlearn: 0.2789293\ttotal: 1m 48s\tremaining: 43.3s\n",
            "143:\tlearn: 0.2785477\ttotal: 1m 49s\tremaining: 42.5s\n",
            "144:\tlearn: 0.2780304\ttotal: 1m 50s\tremaining: 41.7s\n",
            "145:\tlearn: 0.2772995\ttotal: 1m 50s\tremaining: 41s\n",
            "146:\tlearn: 0.2762571\ttotal: 1m 51s\tremaining: 40.2s\n",
            "147:\tlearn: 0.2759810\ttotal: 1m 52s\tremaining: 39.4s\n",
            "148:\tlearn: 0.2754146\ttotal: 1m 52s\tremaining: 38.6s\n",
            "149:\tlearn: 0.2749890\ttotal: 1m 53s\tremaining: 37.9s\n",
            "150:\tlearn: 0.2745602\ttotal: 1m 54s\tremaining: 37.1s\n",
            "151:\tlearn: 0.2742534\ttotal: 1m 55s\tremaining: 36.4s\n",
            "152:\tlearn: 0.2736531\ttotal: 1m 55s\tremaining: 35.6s\n",
            "153:\tlearn: 0.2731715\ttotal: 1m 56s\tremaining: 34.8s\n",
            "154:\tlearn: 0.2726640\ttotal: 1m 57s\tremaining: 34.1s\n",
            "155:\tlearn: 0.2723527\ttotal: 1m 58s\tremaining: 33.3s\n",
            "156:\tlearn: 0.2720184\ttotal: 1m 58s\tremaining: 32.5s\n",
            "157:\tlearn: 0.2717549\ttotal: 1m 59s\tremaining: 31.8s\n",
            "158:\tlearn: 0.2712837\ttotal: 2m\tremaining: 31s\n",
            "159:\tlearn: 0.2708533\ttotal: 2m 1s\tremaining: 30.3s\n",
            "160:\tlearn: 0.2704207\ttotal: 2m 1s\tremaining: 29.5s\n",
            "161:\tlearn: 0.2699676\ttotal: 2m 2s\tremaining: 28.8s\n",
            "162:\tlearn: 0.2696814\ttotal: 2m 3s\tremaining: 28s\n",
            "163:\tlearn: 0.2693007\ttotal: 2m 4s\tremaining: 27.2s\n",
            "164:\tlearn: 0.2688586\ttotal: 2m 4s\tremaining: 26.5s\n",
            "165:\tlearn: 0.2685975\ttotal: 2m 5s\tremaining: 25.7s\n",
            "166:\tlearn: 0.2682859\ttotal: 2m 6s\tremaining: 24.9s\n",
            "167:\tlearn: 0.2678400\ttotal: 2m 6s\tremaining: 24.2s\n",
            "168:\tlearn: 0.2671527\ttotal: 2m 7s\tremaining: 23.4s\n",
            "169:\tlearn: 0.2665282\ttotal: 2m 8s\tremaining: 22.7s\n",
            "170:\tlearn: 0.2662664\ttotal: 2m 9s\tremaining: 21.9s\n",
            "171:\tlearn: 0.2660031\ttotal: 2m 9s\tremaining: 21.1s\n",
            "172:\tlearn: 0.2656128\ttotal: 2m 10s\tremaining: 20.4s\n",
            "173:\tlearn: 0.2652839\ttotal: 2m 11s\tremaining: 19.6s\n",
            "174:\tlearn: 0.2650070\ttotal: 2m 12s\tremaining: 18.9s\n",
            "175:\tlearn: 0.2647240\ttotal: 2m 12s\tremaining: 18.1s\n",
            "176:\tlearn: 0.2643899\ttotal: 2m 13s\tremaining: 17.4s\n",
            "177:\tlearn: 0.2641786\ttotal: 2m 14s\tremaining: 16.6s\n",
            "178:\tlearn: 0.2638780\ttotal: 2m 15s\tremaining: 15.8s\n",
            "179:\tlearn: 0.2636222\ttotal: 2m 15s\tremaining: 15.1s\n",
            "180:\tlearn: 0.2633345\ttotal: 2m 16s\tremaining: 14.3s\n",
            "181:\tlearn: 0.2629834\ttotal: 2m 17s\tremaining: 13.6s\n",
            "182:\tlearn: 0.2627008\ttotal: 2m 17s\tremaining: 12.8s\n",
            "183:\tlearn: 0.2625123\ttotal: 2m 18s\tremaining: 12.1s\n",
            "184:\tlearn: 0.2621271\ttotal: 2m 19s\tremaining: 11.3s\n",
            "185:\tlearn: 0.2617584\ttotal: 2m 20s\tremaining: 10.5s\n",
            "186:\tlearn: 0.2613611\ttotal: 2m 20s\tremaining: 9.79s\n",
            "187:\tlearn: 0.2611075\ttotal: 2m 21s\tremaining: 9.04s\n",
            "188:\tlearn: 0.2604674\ttotal: 2m 22s\tremaining: 8.29s\n",
            "189:\tlearn: 0.2600727\ttotal: 2m 23s\tremaining: 7.53s\n",
            "190:\tlearn: 0.2597851\ttotal: 2m 23s\tremaining: 6.78s\n",
            "191:\tlearn: 0.2595629\ttotal: 2m 24s\tremaining: 6.02s\n",
            "192:\tlearn: 0.2592341\ttotal: 2m 25s\tremaining: 5.27s\n",
            "193:\tlearn: 0.2589392\ttotal: 2m 25s\tremaining: 4.51s\n",
            "194:\tlearn: 0.2586942\ttotal: 2m 26s\tremaining: 3.76s\n",
            "195:\tlearn: 0.2584525\ttotal: 2m 27s\tremaining: 3.01s\n",
            "196:\tlearn: 0.2582430\ttotal: 2m 28s\tremaining: 2.25s\n",
            "197:\tlearn: 0.2580373\ttotal: 2m 28s\tremaining: 1.5s\n",
            "198:\tlearn: 0.2576665\ttotal: 2m 29s\tremaining: 751ms\n",
            "199:\tlearn: 0.2571677\ttotal: 2m 30s\tremaining: 0us\n",
            "F1 Score: 0.741623955524761\n"
          ]
        }
      ],
      "source": [
        "model = CatBoostClassifier(scale_pos_weight=scale_pos_weight, random_state=RANDOM_STATE)\n",
        "\n",
        "param_grid = {\n",
        "    'depth': [3],\n",
        "    'iterations': [200]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, scoring='f1', cv=cv, n_jobs=-1, verbose=10)\n",
        "\n",
        "grid_search.fit(tf_idf_train, target_train)\n",
        "\n",
        "catboost_score = grid_search.best_score_\n",
        "\n",
        "print(\"F1 Score:\", catboost_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLt50GzW8eqD"
      },
      "source": [
        "### Сравнение"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "6LfX4Yoy8eqE",
        "outputId": "eb746996-ed74-4162-aa70-334dd16ee373"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>f1_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>CatBoost</th>\n",
              "      <td>0.742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RandomForest</th>\n",
              "      <td>0.375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LogisticRegression</th>\n",
              "      <td>0.750</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    f1_score\n",
              "CatBoost               0.742\n",
              "RandomForest           0.375\n",
              "LogisticRegression     0.750"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.DataFrame({'f1_score': [catboost_score, forest_score, log_reg_score]},\n",
        "             index=['CatBoost', 'RandomForest', 'LogisticRegression']).round(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfo1OMCR8eqE"
      },
      "source": [
        "Как мы видим наилучшей метрикой обладают модель LogisticRegression, следовательно ее и будем использовать дальше."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2PaohqQ8eqE"
      },
      "source": [
        "### Тест"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xROMAvfbw8UZ"
      },
      "source": [
        "Для увеличения метрики f1 мы можем обучить нашу лучшую модель на кроссвалидации на всем обучающем наборе данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "id": "je8EFCsaw7WZ",
        "outputId": "4c6cc8f3-384b-4078-a918-ac56ecf6785e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "LogisticRegression(class_weight='balanced', random_state=42)"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "log_reg_model.fit(tf_idf_train, target_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CqNfJhoi8eqF",
        "outputId": "fc047c95-29cd-48a6-b42c-56b4bf4dbb9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.75\n"
          ]
        }
      ],
      "source": [
        "prediction = log_reg_model.predict(tf_idf_test)\n",
        "print(round(f1_score(target_test, prediction), 3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erDIgGeG8eqF"
      },
      "source": [
        "### DummyRegressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36FtUtuG8eqF",
        "outputId": "8bcfbc1f-67cb-4330-ceb0-6bfd8f186cf4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.18446546614998857\n"
          ]
        }
      ],
      "source": [
        "dum_prediction = pd.Series(1, index=target_test)\n",
        "\n",
        "print(f1_score(target_test, dum_prediction))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwiuDudB8eqG"
      },
      "source": [
        "Как мы видим, модель которая помечает все строки токсичными, имеет точность всего лишь 0.18"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUsTzd058eqG"
      },
      "source": [
        "## Выводы"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hU9snZ9X8eqG"
      },
      "source": [
        "Задачей проекта было разработать прототип модели машинного обучения, который мог бы предсказывать токсичность комментариев. В ходе работы были выполнены следующие шаги:\n",
        "- Подготовка данных. В процессе подготовки данных были выполнены операции, такие как чтение и изучение данных, лемматизация, очистка и подготовка выборок для обучения модели.\n",
        "- Анализ:\n",
        "    - В данных имеется явный дисбаланс, устранили его с помощью встроенных методов весов в моделях машинного обучения.\n",
        "- Данные были векторизированы.\n",
        "- Перед обучением были разделены выборки в соотношении 1 к 5.\n",
        "- Были обучены и протестированны три модели на кроссвалидации CatBoost, LogisticRegression и RandomForest.\n",
        "- Самой удачной для нашей задачи является модель LogisticRegression c F1 = 0.75, что полностью удовлетворяет условиям задачи."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TFoGXxOVVisz"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "ExecuteTimeLog": [
      {
        "duration": 1661,
        "start_time": "2023-05-30T20:51:37.554Z"
      },
      {
        "duration": 2301,
        "start_time": "2023-05-30T20:52:54.006Z"
      },
      {
        "duration": 818,
        "start_time": "2023-05-30T20:53:28.593Z"
      },
      {
        "duration": 12,
        "start_time": "2023-05-30T20:59:36.857Z"
      },
      {
        "duration": 105,
        "start_time": "2023-05-30T21:29:45.323Z"
      },
      {
        "duration": 10,
        "start_time": "2023-05-30T21:29:49.513Z"
      },
      {
        "duration": 13,
        "start_time": "2023-05-30T21:29:54.440Z"
      },
      {
        "duration": 7,
        "start_time": "2023-05-30T21:29:56.219Z"
      },
      {
        "duration": 140,
        "start_time": "2023-05-30T21:35:42.374Z"
      },
      {
        "duration": 128,
        "start_time": "2023-05-30T21:36:34.378Z"
      },
      {
        "duration": 143,
        "start_time": "2023-05-30T21:36:56.558Z"
      },
      {
        "duration": 114,
        "start_time": "2023-05-30T21:39:19.227Z"
      },
      {
        "duration": 95,
        "start_time": "2023-05-30T21:40:05.687Z"
      },
      {
        "duration": 29,
        "start_time": "2023-05-30T21:40:40.068Z"
      },
      {
        "duration": 47,
        "start_time": "2023-05-30T21:41:00.827Z"
      },
      {
        "duration": 13,
        "start_time": "2023-05-30T21:41:20.177Z"
      },
      {
        "duration": 12,
        "start_time": "2023-05-30T21:41:26.268Z"
      },
      {
        "duration": 252,
        "start_time": "2023-05-30T21:42:15.238Z"
      },
      {
        "duration": 327,
        "start_time": "2023-05-30T21:42:31.172Z"
      },
      {
        "duration": 1086,
        "start_time": "2023-05-30T21:47:28.240Z"
      },
      {
        "duration": 45,
        "start_time": "2023-05-31T03:05:58.003Z"
      },
      {
        "duration": 3413,
        "start_time": "2023-05-31T03:06:10.752Z"
      },
      {
        "duration": 2476,
        "start_time": "2023-05-31T03:06:30.698Z"
      },
      {
        "duration": 75,
        "start_time": "2023-05-31T03:06:33.176Z"
      },
      {
        "duration": 137,
        "start_time": "2023-05-31T03:06:33.253Z"
      },
      {
        "duration": 0,
        "start_time": "2023-05-31T03:06:33.392Z"
      },
      {
        "duration": 0,
        "start_time": "2023-05-31T03:06:33.393Z"
      },
      {
        "duration": 0,
        "start_time": "2023-05-31T03:06:33.395Z"
      },
      {
        "duration": 0,
        "start_time": "2023-05-31T03:06:33.395Z"
      },
      {
        "duration": 0,
        "start_time": "2023-05-31T03:06:33.397Z"
      },
      {
        "duration": 0,
        "start_time": "2023-05-31T03:06:33.397Z"
      },
      {
        "duration": 0,
        "start_time": "2023-05-31T03:06:33.399Z"
      },
      {
        "duration": 0,
        "start_time": "2023-05-31T03:06:33.399Z"
      },
      {
        "duration": 0,
        "start_time": "2023-05-31T03:06:33.400Z"
      },
      {
        "duration": 0,
        "start_time": "2023-05-31T03:06:33.401Z"
      },
      {
        "duration": 0,
        "start_time": "2023-05-31T03:06:33.402Z"
      },
      {
        "duration": 0,
        "start_time": "2023-05-31T03:06:33.403Z"
      },
      {
        "duration": 0,
        "start_time": "2023-05-31T03:06:33.404Z"
      },
      {
        "duration": 0,
        "start_time": "2023-05-31T03:06:33.405Z"
      },
      {
        "duration": 0,
        "start_time": "2023-05-31T03:06:33.406Z"
      },
      {
        "duration": 0,
        "start_time": "2023-05-31T03:06:33.407Z"
      },
      {
        "duration": 0,
        "start_time": "2023-05-31T03:06:33.408Z"
      },
      {
        "duration": 0,
        "start_time": "2023-05-31T03:06:33.409Z"
      },
      {
        "duration": 0,
        "start_time": "2023-05-31T03:06:33.410Z"
      },
      {
        "duration": 0,
        "start_time": "2023-05-31T03:06:33.442Z"
      },
      {
        "duration": 0,
        "start_time": "2023-05-31T03:06:33.443Z"
      },
      {
        "duration": 0,
        "start_time": "2023-05-31T03:06:33.444Z"
      },
      {
        "duration": 0,
        "start_time": "2023-05-31T03:06:33.445Z"
      },
      {
        "duration": 6,
        "start_time": "2023-05-31T03:10:06.061Z"
      },
      {
        "duration": 106,
        "start_time": "2023-05-31T03:10:06.069Z"
      },
      {
        "duration": 11,
        "start_time": "2023-05-31T03:10:06.177Z"
      },
      {
        "duration": 0,
        "start_time": "2023-05-31T03:10:06.190Z"
      },
      {
        "duration": 0,
        "start_time": "2023-05-31T03:10:06.191Z"
      },
      {
        "duration": 0,
        "start_time": "2023-05-31T03:10:06.192Z"
      },
      {
        "duration": 0,
        "start_time": "2023-05-31T03:10:06.193Z"
      },
      {
        "duration": 0,
        "start_time": "2023-05-31T03:10:06.194Z"
      },
      {
        "duration": 0,
        "start_time": "2023-05-31T03:10:06.195Z"
      },
      {
        "duration": 0,
        "start_time": "2023-05-31T03:10:06.196Z"
      },
      {
        "duration": 0,
        "start_time": "2023-05-31T03:10:06.197Z"
      },
      {
        "duration": 0,
        "start_time": "2023-05-31T03:10:06.198Z"
      },
      {
        "duration": 0,
        "start_time": "2023-05-31T03:10:06.199Z"
      },
      {
        "duration": 0,
        "start_time": "2023-05-31T03:10:06.201Z"
      },
      {
        "duration": 0,
        "start_time": "2023-05-31T03:10:06.201Z"
      },
      {
        "duration": 0,
        "start_time": "2023-05-31T03:10:06.202Z"
      },
      {
        "duration": 0,
        "start_time": "2023-05-31T03:10:06.203Z"
      },
      {
        "duration": 0,
        "start_time": "2023-05-31T03:10:06.204Z"
      },
      {
        "duration": 0,
        "start_time": "2023-05-31T03:10:06.206Z"
      },
      {
        "duration": 0,
        "start_time": "2023-05-31T03:10:06.207Z"
      },
      {
        "duration": 0,
        "start_time": "2023-05-31T03:10:06.208Z"
      },
      {
        "duration": 0,
        "start_time": "2023-05-31T03:10:06.208Z"
      },
      {
        "duration": 0,
        "start_time": "2023-05-31T03:10:06.209Z"
      },
      {
        "duration": 0,
        "start_time": "2023-05-31T03:10:06.210Z"
      },
      {
        "duration": 0,
        "start_time": "2023-05-31T03:10:06.211Z"
      },
      {
        "duration": 0,
        "start_time": "2023-05-31T03:10:06.213Z"
      },
      {
        "duration": 2295,
        "start_time": "2023-05-31T03:10:23.918Z"
      },
      {
        "duration": 753,
        "start_time": "2023-05-31T03:10:45.000Z"
      },
      {
        "duration": 15,
        "start_time": "2023-05-31T03:10:45.755Z"
      },
      {
        "duration": 33,
        "start_time": "2023-05-31T03:10:45.772Z"
      },
      {
        "duration": 77,
        "start_time": "2023-05-31T03:10:45.806Z"
      },
      {
        "duration": 217,
        "start_time": "2023-05-31T03:10:45.886Z"
      },
      {
        "duration": 27,
        "start_time": "2023-05-31T03:10:46.105Z"
      },
      {
        "duration": 215,
        "start_time": "2023-05-31T03:10:46.142Z"
      },
      {
        "duration": 5,
        "start_time": "2023-05-31T03:10:46.359Z"
      },
      {
        "duration": 19,
        "start_time": "2023-05-31T03:10:46.366Z"
      },
      {
        "duration": 2424,
        "start_time": "2023-05-31T03:10:46.387Z"
      },
      {
        "duration": 2380,
        "start_time": "2023-05-31T03:10:48.813Z"
      },
      {
        "duration": 658,
        "start_time": "2023-05-31T03:10:51.195Z"
      },
      {
        "duration": 2771,
        "start_time": "2023-05-31T06:50:42.375Z"
      },
      {
        "duration": 2959,
        "start_time": "2023-05-31T06:50:45.148Z"
      },
      {
        "duration": 11,
        "start_time": "2023-05-31T06:50:48.108Z"
      },
      {
        "duration": 15,
        "start_time": "2023-05-31T06:50:48.121Z"
      },
      {
        "duration": 30,
        "start_time": "2023-05-31T06:50:48.138Z"
      },
      {
        "duration": 196,
        "start_time": "2023-05-31T06:50:48.170Z"
      },
      {
        "duration": 22,
        "start_time": "2023-05-31T06:50:48.367Z"
      },
      {
        "duration": 117,
        "start_time": "2023-05-31T06:50:48.390Z"
      },
      {
        "duration": 5,
        "start_time": "2023-05-31T06:50:48.509Z"
      },
      {
        "duration": 15,
        "start_time": "2023-05-31T06:50:48.515Z"
      },
      {
        "duration": 1986,
        "start_time": "2023-05-31T06:50:48.532Z"
      },
      {
        "duration": 2326,
        "start_time": "2023-05-31T06:50:50.520Z"
      },
      {
        "duration": 696,
        "start_time": "2023-05-31T06:50:52.848Z"
      },
      {
        "duration": 556851,
        "start_time": "2023-05-31T06:50:53.546Z"
      },
      {
        "duration": 8,
        "start_time": "2023-05-31T07:01:38.214Z"
      },
      {
        "duration": 0,
        "start_time": "2023-05-31T07:18:11.937Z"
      },
      {
        "duration": 6,
        "start_time": "2023-05-31T07:18:14.567Z"
      },
      {
        "duration": 7,
        "start_time": "2023-05-31T07:18:29.234Z"
      },
      {
        "duration": 729,
        "start_time": "2023-05-31T07:18:29.242Z"
      },
      {
        "duration": 11,
        "start_time": "2023-05-31T07:18:29.973Z"
      },
      {
        "duration": 29,
        "start_time": "2023-05-31T07:18:29.986Z"
      },
      {
        "duration": 82,
        "start_time": "2023-05-31T07:18:30.017Z"
      },
      {
        "duration": 236,
        "start_time": "2023-05-31T07:18:30.100Z"
      },
      {
        "duration": 27,
        "start_time": "2023-05-31T07:18:30.337Z"
      },
      {
        "duration": 154,
        "start_time": "2023-05-31T07:18:30.365Z"
      },
      {
        "duration": 5,
        "start_time": "2023-05-31T07:18:30.521Z"
      },
      {
        "duration": 81,
        "start_time": "2023-05-31T07:18:30.528Z"
      },
      {
        "duration": 56,
        "start_time": "2023-05-31T07:18:30.610Z"
      },
      {
        "duration": 448,
        "start_time": "2023-05-31T07:18:30.668Z"
      },
      {
        "duration": 18221,
        "start_time": "2023-06-02T14:10:45.235Z"
      },
      {
        "duration": 13826,
        "start_time": "2023-06-02T14:11:03.458Z"
      },
      {
        "duration": 2379,
        "start_time": "2023-06-02T14:11:17.286Z"
      },
      {
        "duration": 12,
        "start_time": "2023-06-02T14:11:19.667Z"
      },
      {
        "duration": 14,
        "start_time": "2023-06-02T14:11:19.681Z"
      },
      {
        "duration": 34,
        "start_time": "2023-06-02T14:11:19.697Z"
      },
      {
        "duration": 232,
        "start_time": "2023-06-02T14:11:19.733Z"
      },
      {
        "duration": 29,
        "start_time": "2023-06-02T14:11:19.967Z"
      },
      {
        "duration": 133,
        "start_time": "2023-06-02T14:11:19.997Z"
      },
      {
        "duration": 6,
        "start_time": "2023-06-02T14:11:20.132Z"
      },
      {
        "duration": 6,
        "start_time": "2023-06-02T14:11:20.139Z"
      },
      {
        "duration": 846,
        "start_time": "2023-06-02T14:11:20.146Z"
      },
      {
        "duration": 190,
        "start_time": "2023-06-02T14:11:20.993Z"
      },
      {
        "duration": 4,
        "start_time": "2023-06-02T14:11:21.185Z"
      },
      {
        "duration": 23312,
        "start_time": "2023-06-02T15:42:17.130Z"
      },
      {
        "duration": 8068,
        "start_time": "2023-06-02T15:42:40.444Z"
      },
      {
        "duration": 3081,
        "start_time": "2023-06-02T15:42:48.514Z"
      },
      {
        "duration": 22,
        "start_time": "2023-06-02T15:42:51.605Z"
      },
      {
        "duration": 23,
        "start_time": "2023-06-02T15:42:51.629Z"
      },
      {
        "duration": 47,
        "start_time": "2023-06-02T15:42:51.654Z"
      },
      {
        "duration": 325,
        "start_time": "2023-06-02T15:42:51.703Z"
      },
      {
        "duration": 27,
        "start_time": "2023-06-02T15:42:52.030Z"
      },
      {
        "duration": 168,
        "start_time": "2023-06-02T15:42:52.058Z"
      },
      {
        "duration": 8,
        "start_time": "2023-06-02T15:42:52.230Z"
      },
      {
        "duration": 32,
        "start_time": "2023-06-02T15:42:52.240Z"
      },
      {
        "duration": 700,
        "start_time": "2023-06-02T15:42:52.274Z"
      },
      {
        "duration": 14732,
        "start_time": "2024-05-03T08:56:53.631Z"
      },
      {
        "duration": 4873,
        "start_time": "2024-05-03T08:57:09.127Z"
      },
      {
        "duration": 2230,
        "start_time": "2024-05-03T08:57:23.390Z"
      },
      {
        "duration": 11,
        "start_time": "2024-05-03T08:57:28.294Z"
      },
      {
        "duration": 11,
        "start_time": "2024-05-03T08:57:30.997Z"
      },
      {
        "duration": 5,
        "start_time": "2024-05-03T09:05:18.508Z"
      },
      {
        "duration": 5,
        "start_time": "2024-05-03T09:05:38.610Z"
      },
      {
        "duration": 32,
        "start_time": "2024-05-03T09:05:49.424Z"
      },
      {
        "duration": 219,
        "start_time": "2024-05-03T09:05:58.065Z"
      },
      {
        "duration": 17743506,
        "start_time": "2024-05-03T09:06:19.517Z"
      },
      {
        "duration": 17675,
        "start_time": "2024-05-04T13:56:58.648Z"
      },
      {
        "duration": 5508,
        "start_time": "2024-05-04T13:57:16.327Z"
      },
      {
        "duration": 3392,
        "start_time": "2024-05-04T13:57:21.838Z"
      },
      {
        "duration": 13,
        "start_time": "2024-05-04T13:57:25.232Z"
      },
      {
        "duration": 30,
        "start_time": "2024-05-04T13:57:25.247Z"
      },
      {
        "duration": 47,
        "start_time": "2024-05-04T13:57:25.279Z"
      },
      {
        "duration": 96,
        "start_time": "2024-05-04T13:57:25.328Z"
      },
      {
        "duration": 55,
        "start_time": "2024-05-04T13:57:25.426Z"
      },
      {
        "duration": 152,
        "start_time": "2024-05-04T13:57:25.482Z"
      },
      {
        "duration": 7,
        "start_time": "2024-05-04T13:57:25.637Z"
      },
      {
        "duration": 30,
        "start_time": "2024-05-04T13:57:25.645Z"
      },
      {
        "duration": 578,
        "start_time": "2024-05-04T13:57:25.677Z"
      },
      {
        "duration": 2681145,
        "start_time": "2024-05-04T13:57:26.258Z"
      },
      {
        "duration": 3,
        "start_time": "2024-05-04T14:42:07.406Z"
      },
      {
        "duration": 28,
        "start_time": "2024-05-04T14:42:07.411Z"
      },
      {
        "duration": 21,
        "start_time": "2024-05-04T14:42:07.441Z"
      },
      {
        "duration": 70,
        "start_time": "2024-05-04T14:42:07.464Z"
      },
      {
        "duration": 6788,
        "start_time": "2024-05-04T14:42:07.536Z"
      },
      {
        "duration": 3,
        "start_time": "2024-05-04T14:42:14.326Z"
      },
      {
        "duration": 9,
        "start_time": "2024-05-04T14:42:14.331Z"
      },
      {
        "duration": 192744,
        "start_time": "2024-05-04T14:42:14.341Z"
      },
      {
        "duration": 84552,
        "start_time": "2024-05-04T14:45:27.178Z"
      },
      {
        "duration": 4,
        "start_time": "2024-05-04T14:46:51.731Z"
      },
      {
        "duration": 16,
        "start_time": "2024-05-04T14:46:51.737Z"
      },
      {
        "duration": 818464,
        "start_time": "2024-05-04T14:46:51.755Z"
      },
      {
        "duration": 12,
        "start_time": "2024-05-04T15:00:30.221Z"
      },
      {
        "duration": 35145,
        "start_time": "2024-05-04T15:00:30.234Z"
      },
      {
        "duration": 101,
        "start_time": "2024-05-04T15:01:05.384Z"
      },
      {
        "duration": 22,
        "start_time": "2024-05-04T15:01:05.487Z"
      }
    ],
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": true,
      "title_cell": "Содержание",
      "title_sidebar": "Contents",
      "toc_cell": true,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "302.391px"
      },
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}